{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbOI7QiQgBHq",
        "outputId": "21c0e019-b776-47b7-ce88-64ef99a39edf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.colab import drive\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "import xgboost as xgb\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# csv locations can be updated\n",
        "df_html_0 = pd.read_csv(\"/content/drive/MyDrive/dataminingPhising/features/html_features_0_10000.csv\")  # Load your dataset\n",
        "df_html_10000 = pd.read_csv(\"/content/drive/MyDrive/dataminingPhising/features/html_features_0_10000.csv\")  # Load your dataset\n",
        "df_html_20000 = pd.read_csv(\"/content/drive/MyDrive/dataminingPhising/features/html_features_10000_20000.csv\")  # Load your dataset\n",
        "df_html_30000 = pd.read_csv(\"/content/drive/MyDrive/dataminingPhising/features/html_features_20000_30000.csv\")  # Load your dataset"
      ],
      "metadata": {
        "id": "mifQMSjzgMTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features_0 = pd.read_csv(\"/content/drive/MyDrive/dataminingPhising/features/url_features_0_10000.csv\")\n",
        "df_features_10000 = pd.read_csv(\"/content/drive/MyDrive/dataminingPhising/features/url_features_10000_20000.csv\")\n",
        "df_features_20000 = pd.read_csv(\"/content/drive/MyDrive/dataminingPhising/features/url_features_20000_30000.csv\")\n",
        "df_features_30000 = pd.read_csv(\"/content/drive/MyDrive/dataminingPhising/features/url_features_30000_80000.csv\")"
      ],
      "metadata": {
        "id": "pnSf_RfGZIQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge all dataframes into one\n",
        "merged_df_html = pd.concat([df_html_0 , df_html_10000, df_html_20000, df_html_30000], ignore_index=True)\n",
        "merged_df_features = pd.concat([df_features_0, df_features_10000, df_features_20000, df_features_30000], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "43akLgOKYmDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df_html.drop('rec_id', axis=1, inplace=True)\n",
        "merged_df_features.drop('rec_id', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "NOeyjVCU7AIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(train_df):\n",
        "\n",
        "  # Split labels and features\n",
        "  labels = train_df['phishing']\n",
        "  features = train_df.drop('phishing', axis=1)\n",
        "\n",
        "  # Split the data into training and testing sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
        "\n",
        "  # Standardize the features\n",
        "  scaler = StandardScaler()\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "  return X_train, y_train, X_test, y_test\n",
        "\n"
      ],
      "metadata": {
        "id": "VMFdb1_pAcMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "html_train_X, html_train_y, html_test_X, html_test_y = preprocess(merged_df_html)\n",
        "features_train_X, features_train_y, features_test_X, features_test_y = preprocess(merged_df_features)\n",
        "#"
      ],
      "metadata": {
        "id": "KEiXRSMdAJzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"k-NN (k=1)\": KNeighborsClassifier(n_neighbors=1),\n",
        "    \"k-NN (k=3)\": KNeighborsClassifier(n_neighbors=3),\n",
        "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"MLP Neural Network\": MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": xgb.XGBClassifier(random_state=42)\n",
        "}"
      ],
      "metadata": {
        "id": "z1v5d9YIdHY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_models(models, X_train, y_train, X_test, y_test):\n",
        "  for model_name, model in models.items():\n",
        "      # Train the model\n",
        "      model.fit(features_train_X, features_train_y)\n",
        "\n",
        "      # Predict on the training set\n",
        "      y_train_pred = model.predict(features_train_X)\n",
        "      # Calculate training accuracy\n",
        "      train_accuracy = accuracy_score(features_train_y, y_train_pred)\n",
        "\n",
        "      # Predict on the test set\n",
        "      y_test_pred = model.predict(features_test_X)\n",
        "      # Calculate testing accuracy\n",
        "      test_accuracy = accuracy_score(features_test_y, y_test_pred)\n",
        "      print(f\"ID of {model_name}: {id(model)}\")  # Print the ID\n",
        "\n",
        "      # Print the accuracies for each model\n",
        "      print(f\"{model_name} - Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "g2_sAjAmdZkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_models(models, features_train_X, features_train_y, features_test_X, features_test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dMyDNxnieLu",
        "outputId": "7688c97d-4b43-4ffd-cbb1-1eafa5b21ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID of Decision Tree: 135334041494928\n",
            "Decision Tree - Train Accuracy: 0.9836, Test Accuracy: 0.8803\n",
            "ID of k-NN (k=1): 135334041497040\n",
            "k-NN (k=1) - Train Accuracy: 0.9781, Test Accuracy: 0.8906\n",
            "ID of k-NN (k=3): 135334041497088\n",
            "k-NN (k=3) - Train Accuracy: 0.9364, Test Accuracy: 0.8948\n",
            "ID of Gaussian Naive Bayes: 135334041497136\n",
            "Gaussian Naive Bayes - Train Accuracy: 0.7131, Test Accuracy: 0.7123\n",
            "ID of Logistic Regression: 135334041493968\n",
            "Logistic Regression - Train Accuracy: 0.8456, Test Accuracy: 0.8466\n",
            "ID of MLP Neural Network: 135334041486864\n",
            "MLP Neural Network - Train Accuracy: 0.9518, Test Accuracy: 0.9080\n",
            "ID of Random Forest: 135334041489504\n",
            "Random Forest - Train Accuracy: 0.9836, Test Accuracy: 0.9158\n",
            "ID of XGBoost: 135334041486720\n",
            "XGBoost - Train Accuracy: 0.9323, Test Accuracy: 0.9150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xswO2WH39Dn",
        "outputId": "9170d659-45f6-4c96-c453-d000f9ea7da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.20851214, -0.6244988 , -0.22609012, ..., -0.10972259,\n",
              "        -0.43253947,  0.20000458],\n",
              "       [-0.89995137, -0.25904994,  3.29139662, ..., -0.10972259,\n",
              "        -0.43253947, -1.19032417],\n",
              "       [-0.20851214,  0.10639891, -0.22609012, ..., -0.10972259,\n",
              "        -0.43253947,  0.20000458],\n",
              "       ...,\n",
              "       [-0.20851214, -0.6244988 , -0.22609012, ..., -0.10972259,\n",
              "        -0.43253947,  0.20000458],\n",
              "       [ 1.17436632, -0.6244988 , -0.22609012, ..., -0.10972259,\n",
              "        -0.43253947,  2.9806621 ],\n",
              "       [-0.20851214, -0.6244988 , -0.22609012, ..., -0.10972259,\n",
              "        -0.43253947,  0.20000458]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models2 = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"k-NN (k=1)\": KNeighborsClassifier(n_neighbors=1),\n",
        "    \"k-NN (k=3)\": KNeighborsClassifier(n_neighbors=3),\n",
        "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"MLP Neural Network\": MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": xgb.XGBClassifier(random_state=42)\n",
        "}"
      ],
      "metadata": {
        "id": "BAQW56oc5B4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_remove = [\n",
        "    'qty_/_domain', 'qty_?_domain', 'qty_=_domain', 'qty_@_domain',\n",
        "    'qty_&_domain', 'qty_!_domain', 'qty_ _domain', 'qty_~_domain',\n",
        "    'qty_,_domain', 'qty_+_domain', 'qty_*_domain', 'qty_#_domain',\n",
        "    'qty_$_domain', 'qty_%_domain'  # ... add any other columns with only '0' values\n",
        "]\n",
        "\n",
        "\n",
        "merged_df_features.drop(columns=columns_to_remove, inplace=True)\n",
        "\n",
        "features_train_X, features_train_y, features_test_X, features_test_y = preprocess(merged_df_features)\n",
        "\n",
        "evaluate_models(models2, features_train_X, features_train_y, features_test_X, features_test_y)\n"
      ],
      "metadata": {
        "id": "jeWPP-13f1KV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e75b7f3-0d95-4a5a-89c4-1b954969919a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID of Decision Tree: 135333808204016\n",
            "Decision Tree - Train Accuracy: 0.9836, Test Accuracy: 0.8823\n",
            "ID of k-NN (k=1): 135333808199168\n",
            "k-NN (k=1) - Train Accuracy: 0.9781, Test Accuracy: 0.8904\n",
            "ID of k-NN (k=3): 135333808199408\n",
            "k-NN (k=3) - Train Accuracy: 0.9364, Test Accuracy: 0.8946\n",
            "ID of Gaussian Naive Bayes: 135333808200896\n",
            "Gaussian Naive Bayes - Train Accuracy: 0.7131, Test Accuracy: 0.7123\n",
            "ID of Logistic Regression: 135333808196384\n",
            "Logistic Regression - Train Accuracy: 0.8456, Test Accuracy: 0.8466\n",
            "ID of MLP Neural Network: 135333808197008\n",
            "MLP Neural Network - Train Accuracy: 0.9475, Test Accuracy: 0.9102\n",
            "ID of Random Forest: 135333808197392\n",
            "Random Forest - Train Accuracy: 0.9835, Test Accuracy: 0.9152\n",
            "ID of XGBoost: 135333808198784\n",
            "XGBoost - Train Accuracy: 0.9323, Test Accuracy: 0.9150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decision_tree = DecisionTreeClassifier(criterion='entropy', min_samples_split=4, random_state=32)\n",
        "# decision_tree.fit(features_train_X, features_train_y)\n",
        "\n",
        "# # Calculate accuracy on the test set\n",
        "# y_pred = decision_tree.predict(features_test_X)\n",
        "# accuracy = accuracy_score(features_test_y, y_pred)\n",
        "# print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "uITPOq-90SG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decision_tree_2 = DecisionTreeClassifier(criterion='entropy', min_samples_split=32, random_state=32)\n",
        "# decision_tree_2.fit(features_train_X, features_train_y)\n",
        "\n",
        "# # Calculate accuracy on the test set\n",
        "# y_pred = decision_tree_2.predict(features_test_X)\n",
        "# accuracy = accuracy_score(features_test_y, y_pred)\n",
        "# print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "-dNF9Z_R0qA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aG4GZOx6_UY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def preprocess_2(train_df):\n",
        "\n",
        "#   # Split labels and features\n",
        "#   labels = train_df['phishing']\n",
        "#   features = train_df.drop('phishing', axis=1)\n",
        "\n",
        "#   # Split the data into training and testing sets\n",
        "#   X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
        "\n",
        "\n",
        "#   # Standardize the features\n",
        "#   scaler = StandardScaler()\n",
        "#   X_train = scaler.fit_transform(X_train)\n",
        "#   X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "#   return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "B7x4lMy71a4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yiNre8_f25R8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}