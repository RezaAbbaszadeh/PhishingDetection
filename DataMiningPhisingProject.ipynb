{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbOI7QiQgBHq",
        "outputId": "5ab5e884-4221-4413-f94d-8e7af1a53e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn==1.3.1 in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.1) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.1) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.1) (3.5.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Fix error AttributeError: 'super' object has no attribute '__sklearn_tags__'\n",
        "# https://stackoverflow.com/questions/79290968/super-object-has-no-attribute-sklearn-tags\n",
        "!pip install scikit-learn==1.3.1\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.colab import drive\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.utils import resample\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mifQMSjzgMTV"
      },
      "outputs": [],
      "source": [
        "merged_df_html = pd.read_csv(\"/content/merged_df_html.csv\")\n",
        "merged_df_features = pd.read_csv(\"/content/merged_df_features.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VMFdb1_pAcMO"
      },
      "outputs": [],
      "source": [
        "def preprocess_html(train_df):\n",
        "  columns_to_remove = [\n",
        "    'phishing', 'rec_id', 'ExtFavicon',\n",
        "    ]\n",
        "\n",
        "  # Split labels and features\n",
        "  labels = train_df['phishing']\n",
        "  features = train_df.drop(columns_to_remove, axis=1)\n",
        "\n",
        "  # Split the data into training and testing sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
        "\n",
        "  columns_to_scale = [\n",
        "    'total_forms', 'total_hyperlinks'\n",
        "  ]\n",
        "\n",
        "  # Standardize the features\n",
        "  scaler = StandardScaler()\n",
        "  X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
        "  X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n",
        "\n",
        "  selector = SelectKBest(mutual_info_classif, k=25)\n",
        "  X_new = selector.fit_transform(X_train, y_train)\n",
        "  selected_feature_indices = selector.get_support(indices=True)\n",
        "  selected_feature_names = X_train.columns[selected_feature_indices]\n",
        "\n",
        "  X_train = X_train[selected_feature_names]\n",
        "  X_test = X_test[selected_feature_names]\n",
        "  return X_train, y_train, X_test, y_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KEiXRSMdAJzL"
      },
      "outputs": [],
      "source": [
        "html_train_X, html_train_y, html_test_X, html_test_y = preprocess_html(merged_df_html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z1v5d9YIdHY9"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"k-NN (k=1)\": KNeighborsClassifier(n_neighbors=1),\n",
        "    \"k-NN (k=3)\": KNeighborsClassifier(n_neighbors=3),\n",
        "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"MLP Neural Network\": MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": xgb.XGBClassifier(random_state=42)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "g2_sAjAmdZkF"
      },
      "outputs": [],
      "source": [
        "def evaluate_models(models, X_train, y_train, X_test, y_test):\n",
        "  for model_name, model in models.items():\n",
        "      # Train the model\n",
        "      model.fit(X_train, y_train)\n",
        "\n",
        "      # Predict on the training set\n",
        "      y_train_pred = model.predict(X_train)\n",
        "      # Calculate training accuracy\n",
        "      train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "      # Predict on the test set\n",
        "      y_test_pred = model.predict(X_test)\n",
        "      # Calculate testing accuracy\n",
        "      test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "      print(f\"ID of {model_name}: {id(model)}\")  # Print the ID\n",
        "\n",
        "      # Print the accuracies for each model\n",
        "      print(f\"{model_name} - Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9gL-lrhZb51J"
      },
      "outputs": [],
      "source": [
        "def evaluate_models_2(models, X_train, y_train, X_test, y_test):\n",
        "    print(f\"{'Model':<20} {'Set':<10} {'Pre (%)':<10} {'Recall (%)':<10} {'F1-Score (%)':<15} {'AUC (%)':<10} {'ACC (%)':<10}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "\n",
        "        # Evaluate on test set\n",
        "        y_test_pred = model.predict(X_test)\n",
        "        y_test_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
        "        test_precision = precision_score(y_test, y_test_pred) * 100\n",
        "        test_recall = recall_score(y_test, y_test_pred) * 100\n",
        "        test_f1 = f1_score(y_test, y_test_pred) * 100\n",
        "        test_auc = roc_auc_score(y_test, y_test_prob) * 100 if y_test_prob is not None else \"-\"\n",
        "        test_accuracy = accuracy_score(y_test, y_test_pred) * 100\n",
        "\n",
        "        # Print test set metrics\n",
        "        print(f\"{model_name:<20} {'Test':<10} {test_precision:<10.2f} {test_recall:<10.2f} {test_f1:<15.2f} {test_auc:<10} {test_accuracy:<10.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2dMyDNxnieLu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3c82d17-f296-412b-d1e4-68aa85a5629c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID of Decision Tree: 133527859288944\n",
            "Decision Tree - Train Accuracy: 0.9830, Test Accuracy: 0.9341\n",
            "ID of k-NN (k=1): 133527859289856\n",
            "k-NN (k=1) - Train Accuracy: 0.9643, Test Accuracy: 0.9224\n",
            "ID of k-NN (k=3): 133527859282704\n",
            "k-NN (k=3) - Train Accuracy: 0.9397, Test Accuracy: 0.9102\n",
            "ID of Gaussian Naive Bayes: 133527859291536\n",
            "Gaussian Naive Bayes - Train Accuracy: 0.8271, Test Accuracy: 0.8244\n",
            "ID of Logistic Regression: 133527859286544\n",
            "Logistic Regression - Train Accuracy: 0.8683, Test Accuracy: 0.8646\n",
            "ID of MLP Neural Network: 133527859287600\n",
            "MLP Neural Network - Train Accuracy: 0.9636, Test Accuracy: 0.9390\n",
            "ID of Random Forest: 133527859287312\n",
            "Random Forest - Train Accuracy: 0.9830, Test Accuracy: 0.9526\n",
            "ID of XGBoost: 133527859286976\n",
            "XGBoost - Train Accuracy: 0.9752, Test Accuracy: 0.9468\n"
          ]
        }
      ],
      "source": [
        "evaluate_models(models, html_train_X, html_train_y, html_test_X, html_test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4aTLP6HscUd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae94846-cc7e-4017-97c0-9f8fb6af9698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model                Set        Pre (%)    Recall (%) F1-Score (%)    AUC (%)    ACC (%)   \n",
            "--------------------------------------------------------------------------------\n",
            "Decision Tree        Test       91.25      91.11      91.18           94.2712681187075 93.41     \n",
            "k-NN (k=1)           Test       91.67      87.17      89.36           91.21750957523614 92.24     \n",
            "k-NN (k=3)           Test       85.89      90.93      88.34           95.73015330804962 91.02     \n",
            "Gaussian Naive Bayes Test       71.49      88.24      78.99           88.8179134806562 82.44     \n",
            "Logistic Regression  Test       82.22      81.39      81.80           92.18412064443018 86.46     \n",
            "MLP Neural Network   Test       92.46      91.13      91.79           97.77512094431452 93.90     \n",
            "Random Forest        Test       94.48      92.73      93.60           98.76648852952817 95.26     \n",
            "XGBoost              Test       93.60      92.08      92.83           98.47102278912459 94.68     \n"
          ]
        }
      ],
      "source": [
        "evaluate_models_2(models, html_train_X, html_train_y, html_test_X, html_test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "D1_3sA5sdriT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "385b4880-e6ad-40d6-bcf4-6cb4cec17bf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [21:38:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9468125\n",
            "Precision: 0.9359714673913043\n",
            "Recall: 0.9208020050125313\n",
            "F1 Score: 0.928324770487661\n",
            "Confusion Matrix:\n",
            "[[9638  377]\n",
            " [ 474 5511]]\n"
          ]
        }
      ],
      "source": [
        "model_1 =  XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "model_1.fit(html_train_X, html_train_y)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model_1.predict(html_test_X)\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(html_test_y, y_pred)\n",
        "precision = precision_score(html_test_y, y_pred)\n",
        "recall = recall_score(html_test_y, y_pred)\n",
        "f1 = f1_score(html_test_y, y_pred)\n",
        "conf_matrix = confusion_matrix(html_test_y, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "glMkC1xG92o6"
      },
      "outputs": [],
      "source": [
        "def preprocess_features(train_df):\n",
        "  columns_to_remove = [\n",
        "      'phishing', 'rec_id',\n",
        "    'qty_/_domain', 'qty_?_domain', 'qty_=_domain', 'qty_@_domain',\n",
        "    'qty_&_domain', 'qty_!_domain', 'qty_ _domain', 'qty_~_domain',\n",
        "    'qty_,_domain', 'qty_+_domain', 'qty_*_domain', 'qty_#_domain',\n",
        "    'qty_$_domain', 'qty_%_domain',\n",
        "      'time_response'\t,'domain_spf'\t,'asn_ip'\t,'time_domain_activation'\t,\n",
        "      'time_domain_expiration'\t,'qty_ip_resolved'\t,'qty_nameservers',\n",
        "      'qty_mx_servers',\t'ttl_hostname'\t,'tls_ssl_certificate',\n",
        "      'qty_redirects',\t'url_google_index',\t'domain_google_index',\t'url_shortened'\n",
        "]\n",
        "\n",
        "   # Split labels and features\n",
        "  labels = train_df['phishing']\n",
        "  features = train_df.drop(columns_to_remove, axis=1)\n",
        "\n",
        "  # Split the data into training and testing sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  X_train  = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  return X_train, y_train, X_test, y_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jeWPP-13f1KV"
      },
      "outputs": [],
      "source": [
        "features_train_X, features_train_y, features_test_X, features_test_y = preprocess_features(merged_df_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BAQW56oc5B4c"
      },
      "outputs": [],
      "source": [
        "models2 = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"k-NN (k=1)\": KNeighborsClassifier(n_neighbors=1),\n",
        "    \"k-NN (k=3)\": KNeighborsClassifier(n_neighbors=3),\n",
        "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"MLP Neural Network\": MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": xgb.XGBClassifier(random_state=42)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RRcyFtz7AKdV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f7957a4-ff0d-4452-820d-68e827b1d3b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID of Decision Tree: 133527854693968\n",
            "Decision Tree - Train Accuracy: 0.9836, Test Accuracy: 0.8818\n",
            "ID of k-NN (k=1): 133527854951984\n",
            "k-NN (k=1) - Train Accuracy: 0.9781, Test Accuracy: 0.8902\n",
            "ID of k-NN (k=3): 133527854941568\n",
            "k-NN (k=3) - Train Accuracy: 0.9365, Test Accuracy: 0.8947\n",
            "ID of Gaussian Naive Bayes: 133527854951792\n",
            "Gaussian Naive Bayes - Train Accuracy: 0.7076, Test Accuracy: 0.7078\n",
            "ID of Logistic Regression: 133527854944112\n",
            "Logistic Regression - Train Accuracy: 0.8456, Test Accuracy: 0.8462\n",
            "ID of MLP Neural Network: 133527854944496\n",
            "MLP Neural Network - Train Accuracy: 0.9474, Test Accuracy: 0.9098\n",
            "ID of Random Forest: 133527854944544\n",
            "Random Forest - Train Accuracy: 0.9836, Test Accuracy: 0.9145\n",
            "ID of XGBoost: 133527854944448\n",
            "XGBoost - Train Accuracy: 0.9323, Test Accuracy: 0.9150\n"
          ]
        }
      ],
      "source": [
        "evaluate_models(models2, features_train_X, features_train_y, features_test_X, features_test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "d0B2EKeXczTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d465c17d-7e7f-479c-c97c-004f2cb9f94a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model                Set        Pre (%)    Recall (%) F1-Score (%)    AUC (%)    ACC (%)   \n",
            "--------------------------------------------------------------------------------\n",
            "Decision Tree        Test       84.73      83.33      84.02           88.36984966835186 88.18     \n",
            "k-NN (k=1)           Test       85.30      85.24      85.27           88.25303388525944 89.02     \n",
            "k-NN (k=3)           Test       86.37      85.20      85.78           93.33439662505845 89.47     \n",
            "Gaussian Naive Bayes Test       83.41      27.01      40.81           87.75447984896942 70.78     \n",
            "Logistic Regression  Test       82.86      74.09      78.23           91.95659894641825 84.62     \n",
            "MLP Neural Network   Test       87.57      88.34      87.96           96.4696590425941 90.98     \n",
            "Random Forest        Test       89.11      87.80      88.45           96.74086044926298 91.45     \n",
            "XGBoost              Test       89.31      87.69      88.49           97.2249493358518 91.50     \n"
          ]
        }
      ],
      "source": [
        "evaluate_models_2(models2, features_train_X, features_train_y, features_test_X, features_test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-Pi6mKeRTbr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee367cc0-837a-4b3d-f49a-b7aa77527652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [21:45:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.91496875\n",
            "Precision: 0.8931284677763551\n",
            "Recall: 0.8768856855514583\n",
            "F1 Score: 0.8849325495834567\n",
            "Confusion Matrix:\n",
            "[[18816  1252]\n",
            " [ 1469 10463]]\n"
          ]
        }
      ],
      "source": [
        "model_2 =  XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "model_2.fit(features_train_X, features_train_y)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model_2.predict(features_test_X)\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(features_test_y, y_pred)\n",
        "precision = precision_score(features_test_y, y_pred)\n",
        "recall = recall_score(features_test_y, y_pred)\n",
        "f1 = f1_score(features_test_y, y_pred)\n",
        "conf_matrix = confusion_matrix(features_test_y, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "walvCJJe4CGJ"
      },
      "outputs": [],
      "source": [
        "merged_df = pd.merge(merged_df_html, merged_df_features, on='rec_id', how='outer')\n",
        "\n",
        "# Handle phishing label (assuming both phishing labels should match)\n",
        "# If they don't match, prioritize one, or handle conflicts as needed\n",
        "merged_df['phishing'] = merged_df['phishing_x'].combine_first(merged_df['phishing_y'])\n",
        "\n",
        "# Drop duplicate phishing columns\n",
        "merged_df.drop(columns=['phishing_x', 'phishing_y'], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Pb_lTf_m4OsV"
      },
      "outputs": [],
      "source": [
        "def preprocess_merged_df(train_df):\n",
        "  columns_to_remove = [\n",
        "      'phishing', 'rec_id',\n",
        "    'qty_/_domain', 'qty_?_domain', 'qty_=_domain', 'qty_@_domain',\n",
        "    'qty_&_domain', 'qty_!_domain', 'qty_ _domain', 'qty_~_domain',\n",
        "    'qty_,_domain', 'qty_+_domain', 'qty_*_domain', 'qty_#_domain',\n",
        "    'qty_$_domain', 'qty_%_domain',\n",
        "      'time_response'\t,'domain_spf'\t,'asn_ip'\t,'time_domain_activation'\t,\n",
        "      'time_domain_expiration'\t,'qty_ip_resolved'\t,'qty_nameservers',\n",
        "      'qty_mx_servers',\t'ttl_hostname'\t,'tls_ssl_certificate',\n",
        "      'qty_redirects',\t'url_google_index',\t'domain_google_index',\t'url_shortened', 'ExtFavicon'\n",
        "]\n",
        "\n",
        "   # Split labels and features\n",
        "  labels = train_df['phishing']\n",
        "  features = train_df.drop(columns_to_remove, axis=1)\n",
        "\n",
        "  # Split the data into training and testing sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
        "  feature_names = X_train.columns\n",
        "\n",
        "  feature_columns_to_scale = merged_df_features.columns.difference(columns_to_remove)\n",
        "  html_columns_to_scale = [\n",
        "    'total_forms', 'total_hyperlinks'\n",
        "  ]\n",
        "  columns_to_scale = feature_columns_to_scale.tolist() + html_columns_to_scale\n",
        "\n",
        "  # Standardize the features\n",
        "  scaler = StandardScaler()\n",
        "  X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
        "  X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n",
        "\n",
        "  imputer = SimpleImputer(strategy='most_frequent')\n",
        "  X_train = imputer.fit_transform(X_train)\n",
        "  X_test = imputer.transform(X_test)\n",
        "\n",
        "  # Convert back to DataFrame with original column names\n",
        "  X_train = pd.DataFrame(X_train, columns=feature_names)\n",
        "  X_test = pd.DataFrame(X_test, columns=feature_names)\n",
        "\n",
        "  selector = SelectKBest(mutual_info_classif, k=40)\n",
        "  X_new = selector.fit_transform(X_train, y_train)\n",
        "  selected_feature_indices = selector.get_support(indices=True)\n",
        "  selected_feature_names = X_train.columns[selected_feature_indices]\n",
        "\n",
        "  X_train = X_train[selected_feature_names]\n",
        "  X_test = X_test[selected_feature_names]\n",
        "\n",
        "\n",
        "  return X_train, y_train, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "R8LZfBRhpKgy"
      },
      "outputs": [],
      "source": [
        "merged_train_X, merged_train_y, merged_test_X, merged_test_y = preprocess_merged_df(merged_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7KnkLUtopOfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5a35902-ba1b-4d11-e80f-a5cc5334e8cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [21:45:54] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9273333333333333\n",
            "Precision: 0.9138246041412911\n",
            "Recall: 0.8899762752075919\n",
            "F1 Score: 0.9017427884615385\n",
            "Confusion Matrix:\n",
            "[[21380  1132]\n",
            " [ 1484 12004]]\n"
          ]
        }
      ],
      "source": [
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_model.fit(merged_train_X, merged_train_y)\n",
        "\n",
        "predictions = xgb_model.predict(merged_test_X)\n",
        "\n",
        "accuracy = accuracy_score(merged_test_y, predictions)\n",
        "precision = precision_score(merged_test_y, predictions)\n",
        "recall = recall_score(merged_test_y, predictions)\n",
        "f1 = f1_score(merged_test_y, predictions)\n",
        "conf_matrix = confusion_matrix(merged_test_y, predictions)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mxes76XCuAE3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cd8c57e-3e9c-4284-b5d6-c1b2ecac68a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [21:45:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [21:46:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.89425\n",
            "Precision: 0.9338531863404141\n",
            "Recall: 0.7724644128113879\n",
            "F1 Score: 0.8455264759586123\n",
            "Confusion Matrix:\n",
            "[[21774   738]\n",
            " [ 3069 10419]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "voting_model = VotingClassifier(\n",
        "    estimators=[('xgboost_1', model_1), ('rf_1', models['Random Forest']),\n",
        "                ('gaussian_1', models['Gaussian Naive Bayes']), ('logistic_1', models['Logistic Regression']),\n",
        "\n",
        "                ('rf_2', models['Random Forest']), ('gaussian_2', models['Gaussian Naive Bayes']),\n",
        "                ('logistic_2', models['Logistic Regression']), ('xgboost_2', model_2)\n",
        "                ],\n",
        "    voting='hard'  # Use 'soft' for probability averaging if needed\n",
        ")\n",
        "\n",
        "# Train the voting classifier\n",
        "voting_model.fit(merged_train_X, merged_train_y)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = voting_model.predict(merged_test_X)\n",
        "\n",
        "accuracy = accuracy_score(merged_test_y, y_pred)\n",
        "precision = precision_score(merged_test_y, y_pred)\n",
        "recall = recall_score(merged_test_y, y_pred)\n",
        "f1 = f1_score(merged_test_y, y_pred)\n",
        "conf_matrix = confusion_matrix(merged_test_y, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "whLcPmV-6Jdx"
      },
      "execution_count": 21,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}