{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbOI7QiQgBHq",
        "outputId": "61f675ca-3949-4078-a2aa-a805998a8eff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.colab import drive\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.cluster import KMeans\n",
        "import xgboost as xgb\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mifQMSjzgMTV"
      },
      "outputs": [],
      "source": [
        "# csv locations can be updated\n",
        "df_html_0 = pd.read_csv(\"/content/drive/MyDrive/dataminingPhising/features/html_features_0_10000.csv\")  # Load your dataset\n",
        "df_html_10000 = pd.read_csv(\"/content/drive/MyDrive/dataminingPhising/features/html_features_0_10000.csv\")  # Load your dataset\n",
        "df_html_20000 = pd.read_csv(\"/content/drive/MyDrive/dataminingPhising/features/html_features_10000_20000.csv\")  # Load your dataset\n",
        "df_html_30000 = pd.read_csv(\"/content/drive/MyDrive/dataminingPhising/features/html_features_20000_30000.csv\")  # Load your dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pnSf_RfGZIQN"
      },
      "outputs": [],
      "source": [
        "df_features_0 = pd.read_csv(\"/content/drive/MyDrive/dataminingPhising/features/url_features_0_10000.csv\")\n",
        "df_features_10000 = pd.read_csv(\"/content/drive/MyDrive/dataminingPhising/features/url_features_10000_20000.csv\")\n",
        "df_features_20000 = pd.read_csv(\"/content/drive/MyDrive/dataminingPhising/features/url_features_20000_30000.csv\")\n",
        "df_features_30000 = pd.read_csv(\"/content/drive/MyDrive/dataminingPhising/features/url_features_30000_80000.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "43akLgOKYmDt"
      },
      "outputs": [],
      "source": [
        "# Merge all dataframes into one\n",
        "merged_df_html = pd.concat([df_html_0 , df_html_10000, df_html_20000, df_html_30000], ignore_index=True)\n",
        "merged_df_features = pd.concat([df_features_0, df_features_10000, df_features_20000, df_features_30000], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VMFdb1_pAcMO"
      },
      "outputs": [],
      "source": [
        "def preprocess_html(train_df):\n",
        "  columns_to_remove = [\n",
        "    'phishing', 'rec_id', 'ExtFavicon',\n",
        "    ]\n",
        "\n",
        "  # Split labels and features\n",
        "  labels = train_df['phishing']\n",
        "  features = train_df.drop(columns_to_remove, axis=1)\n",
        "\n",
        "  # Split the data into training and testing sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
        "\n",
        "  columns_to_scale = [\n",
        "    'total_forms', 'total_hyperlinks'\n",
        "  ]\n",
        "\n",
        "  # Standardize the features\n",
        "  scaler = StandardScaler()\n",
        "  X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
        "  X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n",
        "\n",
        "  columns_to_clusters_k15 = ['script_files_ratio',\t'css_files_ratio'\t,'image_files_ratio',\t'anchor_files_ratio',\t'empty_anchor_ratio',\t'null_hyperlink_ratio',\n",
        "  'internal_hyperlink_ratio'\t,'external_hyperlink_ratio'\t,'external_to_internal_ratio', 'PctNullSelfRedirectHyperlinks'\n",
        "                         ]\n",
        "\n",
        "  columns_to_clusters_k5 = ['suspicious_form_ratio'\t,'PctExtHyperlinks'\t,'PctExtResourceUrls']\n",
        "\n",
        "  X_k15 = X_train[columns_to_clusters_k15]\n",
        "  X_k5 = X_train[columns_to_clusters_k5]\n",
        "\n",
        "  kmeans_k15 = KMeans(n_clusters=15, random_state=42)\n",
        "  kmeans_k5 = KMeans(n_clusters=5, random_state=42)\n",
        "\n",
        "  kmeans_k15.fit(X_k15)\n",
        "  kmeans_k5.fit(X_k5)\n",
        "\n",
        "\n",
        "  X_train['cluster_k15'] = kmeans_k15.predict(X_train[columns_to_clusters_k15])  # Use predict for X_train\n",
        "  X_train['cluster_k5'] = kmeans_k5.predict(X_train[columns_to_clusters_k5])  # Use predict for X_train\n",
        "  X_test['cluster_k15'] = kmeans_k15.predict(X_test[columns_to_clusters_k15])  # Use predict for X_test\n",
        "  X_test['cluster_k5'] = kmeans_k5.predict(X_test[columns_to_clusters_k5])  # Use predict for X_test\n",
        "\n",
        "\n",
        "  return X_train, y_train, X_test, y_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KEiXRSMdAJzL"
      },
      "outputs": [],
      "source": [
        "html_train_X, html_train_y, html_test_X, html_test_y = preprocess_html(merged_df_html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z1v5d9YIdHY9"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"k-NN (k=1)\": KNeighborsClassifier(n_neighbors=1),\n",
        "    \"k-NN (k=3)\": KNeighborsClassifier(n_neighbors=3),\n",
        "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"MLP Neural Network\": MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": xgb.XGBClassifier(random_state=42)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g2_sAjAmdZkF"
      },
      "outputs": [],
      "source": [
        "def evaluate_models(models, X_train, y_train, X_test, y_test):\n",
        "  for model_name, model in models.items():\n",
        "      # Train the model\n",
        "      model.fit(X_train, y_train)\n",
        "\n",
        "      # Predict on the training set\n",
        "      y_train_pred = model.predict(X_train)\n",
        "      # Calculate training accuracy\n",
        "      train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "      # Predict on the test set\n",
        "      y_test_pred = model.predict(X_test)\n",
        "      # Calculate testing accuracy\n",
        "      test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "      print(f\"ID of {model_name}: {id(model)}\")  # Print the ID\n",
        "\n",
        "      # Print the accuracies for each model\n",
        "      print(f\"{model_name} - Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dMyDNxnieLu",
        "outputId": "c940afc5-3fb6-42f4-b511-4d05814d9351"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID of Decision Tree: 135598674290784\n",
            "Decision Tree - Train Accuracy: 0.9830, Test Accuracy: 0.9366\n",
            "ID of k-NN (k=1): 135598674293232\n",
            "k-NN (k=1) - Train Accuracy: 0.9645, Test Accuracy: 0.9222\n",
            "ID of k-NN (k=3): 135598674290016\n",
            "k-NN (k=3) - Train Accuracy: 0.9383, Test Accuracy: 0.9074\n",
            "ID of Gaussian Naive Bayes: 135598674294336\n",
            "Gaussian Naive Bayes - Train Accuracy: 0.8307, Test Accuracy: 0.8267\n",
            "ID of Logistic Regression: 135598674823728\n",
            "Logistic Regression - Train Accuracy: 0.8698, Test Accuracy: 0.8674\n",
            "ID of MLP Neural Network: 135598674823104\n",
            "MLP Neural Network - Train Accuracy: 0.9575, Test Accuracy: 0.9330\n",
            "ID of Random Forest: 135598674824112\n",
            "Random Forest - Train Accuracy: 0.9830, Test Accuracy: 0.9527\n",
            "ID of XGBoost: 135598674822672\n",
            "XGBoost - Train Accuracy: 0.9768, Test Accuracy: 0.9473\n"
          ]
        }
      ],
      "source": [
        "# evaluate_models(models, features_train_X, features_train_y, features_test_X, features_test_y)\n",
        "evaluate_models(models, html_train_X, html_train_y, html_test_X, html_test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BAQW56oc5B4c"
      },
      "outputs": [],
      "source": [
        "models2 = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"k-NN (k=1)\": KNeighborsClassifier(n_neighbors=1),\n",
        "    \"k-NN (k=3)\": KNeighborsClassifier(n_neighbors=3),\n",
        "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"MLP Neural Network\": MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": xgb.XGBClassifier(random_state=42)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "glMkC1xG92o6"
      },
      "outputs": [],
      "source": [
        "def preprocess_features(train_df):\n",
        "  columns_to_remove = [\n",
        "      'phishing', 'rec_id',\n",
        "    'qty_/_domain', 'qty_?_domain', 'qty_=_domain', 'qty_@_domain',\n",
        "    'qty_&_domain', 'qty_!_domain', 'qty_ _domain', 'qty_~_domain',\n",
        "    'qty_,_domain', 'qty_+_domain', 'qty_*_domain', 'qty_#_domain',\n",
        "    'qty_$_domain', 'qty_%_domain',\n",
        "      'time_response'\t,'domain_spf'\t,'asn_ip'\t,'time_domain_activation'\t,\n",
        "      'time_domain_expiration'\t,'qty_ip_resolved'\t,'qty_nameservers',\n",
        "      'qty_mx_servers',\t'ttl_hostname'\t,'tls_ssl_certificate',\n",
        "      'qty_redirects',\t'url_google_index',\t'domain_google_index',\t'url_shortened'\n",
        "]\n",
        "\n",
        "   # Split labels and features\n",
        "  labels = train_df['phishing']\n",
        "  features = train_df.drop(columns_to_remove, axis=1)\n",
        "\n",
        "  # Split the data into training and testing sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  X_train  = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  return X_train, y_train, X_test, y_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jeWPP-13f1KV"
      },
      "outputs": [],
      "source": [
        "features_train_X, features_train_y, features_test_X, features_test_y = preprocess_features(merged_df_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRcyFtz7AKdV",
        "outputId": "8cec3c75-14ef-4817-bad6-458add3aa4f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID of Decision Tree: 135598655978656\n",
            "Decision Tree - Train Accuracy: 0.9836, Test Accuracy: 0.8818\n",
            "ID of k-NN (k=1): 135598656194256\n",
            "k-NN (k=1) - Train Accuracy: 0.9781, Test Accuracy: 0.8902\n",
            "ID of k-NN (k=3): 135598656194304\n",
            "k-NN (k=3) - Train Accuracy: 0.9365, Test Accuracy: 0.8947\n",
            "ID of Gaussian Naive Bayes: 135598656194352\n",
            "Gaussian Naive Bayes - Train Accuracy: 0.7076, Test Accuracy: 0.7078\n",
            "ID of Logistic Regression: 135598656197040\n",
            "Logistic Regression - Train Accuracy: 0.8456, Test Accuracy: 0.8465\n",
            "ID of MLP Neural Network: 135598656196992\n",
            "MLP Neural Network - Train Accuracy: 0.9474, Test Accuracy: 0.9098\n",
            "ID of Random Forest: 135598656196944\n",
            "Random Forest - Train Accuracy: 0.9836, Test Accuracy: 0.9145\n",
            "ID of XGBoost: 135598656196848\n",
            "XGBoost - Train Accuracy: 0.9323, Test Accuracy: 0.9150\n"
          ]
        }
      ],
      "source": [
        "evaluate_models(models2, features_train_X, features_train_y, features_test_X, features_test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yiNre8_f25R8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "datamining",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
