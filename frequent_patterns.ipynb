{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       rec_id  qty_._url  qty_-_url  qty___url  qty_/_url  qty_?_url  \\\n",
      "0           1          2          0          0          4          0   \n",
      "1           2          3          0          0          3          0   \n",
      "2           3          3          0          0          4          0   \n",
      "3           4          3          1          0          5          0   \n",
      "4           5          4          0          0          3          0   \n",
      "...       ...        ...        ...        ...        ...        ...   \n",
      "79995   79996          1          0          0          5          0   \n",
      "79996   79997          2          0          1          6          1   \n",
      "79997   79998          2          0          0          4          0   \n",
      "79998   79999          3          1          1          4          0   \n",
      "79999   80000          2          0          0          3          0   \n",
      "\n",
      "       qty_=_url  qty_@_url  qty_&_url  qty_!_url  ...  \\\n",
      "0              0          0          0          0  ...   \n",
      "1              0          0          0          0  ...   \n",
      "2              0          0          0          0  ...   \n",
      "3              0          0          0          0  ...   \n",
      "4              0          0          0          0  ...   \n",
      "...          ...        ...        ...        ...  ...   \n",
      "79995          0          0          0          0  ...   \n",
      "79996          3          0          2          0  ...   \n",
      "79997          0          0          0          0  ...   \n",
      "79998          0          0          0          0  ...   \n",
      "79999          0          0          0          0  ...   \n",
      "\n",
      "       FrequentDomainNameMismatch  FakeLinkInStatusBar  RightClickDisabled  \\\n",
      "0                               0                    0                   0   \n",
      "1                               0                    0                   0   \n",
      "2                               1                    0                   0   \n",
      "3                               0                    0                   0   \n",
      "4                               1                    0                   0   \n",
      "...                           ...                  ...                 ...   \n",
      "79995                           1                    0                   0   \n",
      "79996                           0                    0                   0   \n",
      "79997                           1                    0                   0   \n",
      "79998                           0                    0                   0   \n",
      "79999                           0                    0                   0   \n",
      "\n",
      "       PopUpWindow  SubmitInfoToEmail  IframeOrFrame  MissingTitle  \\\n",
      "0                0                  0              0             0   \n",
      "1                0                  0              0             0   \n",
      "2                0                  0              0             0   \n",
      "3                0                  0              1             0   \n",
      "4                0                  0              1             0   \n",
      "...            ...                ...            ...           ...   \n",
      "79995            0                  0              1             0   \n",
      "79996            0                  0              0             0   \n",
      "79997            0                  0              0             0   \n",
      "79998            0                  1              0             0   \n",
      "79999            0                  0              0             0   \n",
      "\n",
      "       ImagesOnlyInForm  ExtMetaScriptLinkRT  phishing  \n",
      "0                     0             0.333333         1  \n",
      "1                     0             0.333333         0  \n",
      "2                     0             0.090909         0  \n",
      "3                     0             0.288462         0  \n",
      "4                     0             0.743590         0  \n",
      "...                 ...                  ...       ...  \n",
      "79995                 0             0.142857         1  \n",
      "79996                 0             0.076923         1  \n",
      "79997                 0             0.484848         0  \n",
      "79998                 0             0.419355         0  \n",
      "79999                 0             0.785714         1  \n",
      "\n",
      "[80000 rows x 172 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('features/url_features.csv', index_col=0)\n",
    "df2 = pd.read_csv('features/html_features.csv', index_col=0)\n",
    "\n",
    "# Merge DataFrames on 'rec_id'\n",
    "merged_df = pd.merge(df1, df2, on='rec_id', how='outer')\n",
    "\n",
    "# Handle phishing label (assuming both phishing labels should match)\n",
    "# If they don't match, prioritize one, or handle conflicts as needed\n",
    "merged_df['phishing'] = merged_df['phishing_x'].combine_first(merged_df['phishing_y'])\n",
    "\n",
    "# Drop duplicate phishing columns\n",
    "merged_df.drop(columns=['phishing_x', 'phishing_y'], inplace=True)\n",
    "\n",
    "# Output the final DataFrame\n",
    "print(merged_df)\n",
    "merged_df.to_csv('features/merged_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filepath = \"features/merged_features.csv\"  # Replace with your dataset file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate columns (with different names):\n",
      "Columns ['qty_._url', 'num_dots'] have identical values.\n",
      "Columns ['qty_-_url', 'num_dash'] have identical values.\n",
      "Columns ['qty___url', 'num_underscore'] have identical values.\n",
      "Columns ['qty_&_url', 'num_ampersand'] have identical values.\n",
      "Columns ['qty_#_url', 'num_hash'] have identical values.\n",
      "Columns ['qty_%_url', 'num_percent'] have identical values.\n",
      "Columns ['length_url', 'url_length'] have identical values.\n",
      "Columns ['qty_._domain', 'subdomain_level', 'subdomain_count'] have identical values.\n",
      "Columns ['qty_-_domain', 'num_dash_in_hostname'] have identical values.\n",
      "Columns ['domain_length', 'hostname_length'] have identical values.\n",
      "Columns ['domain_in_ip', 'ip_address', 'ip_address_in_url'] have identical values.\n",
      "Columns ['directory_length', 'path_length'] have identical values.\n",
      "Columns ['params_length', 'query_length'] have identical values.\n",
      "Columns ['qty_params', 'num_query_components'] have identical values.\n",
      "Columns ['at_symbol', 'at_symbol_in_url'] have identical values.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(filepath)\n",
    "df = df.loc[:, df.nunique() > 1]\n",
    "\n",
    "# Step 1: Create a dictionary to store column data as tuples\n",
    "column_map = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    column_values = tuple(df[col])  # Convert column values to a tuple\n",
    "    column_map.setdefault(column_values, []).append(col)\n",
    "\n",
    "# Step 2: Identify columns with duplicate data but different names\n",
    "duplicate_columns = {k: v for k, v in column_map.items() if len(v) > 1}\n",
    "\n",
    "# Display results\n",
    "print(\"Duplicate columns (with different names):\")\n",
    "for values, columns in duplicate_columns.items():\n",
    "    print(f\"Columns {columns} have identical values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 173)\n",
      "(80000, 135)\n",
      "(80000, 118)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(filepath)\n",
    "print(df.shape)\n",
    "df = df.loc[:, df.nunique() > 1]\n",
    "print(df.shape)\n",
    "\n",
    "column_map = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    column_values = tuple(df[col])  # Convert column values to a tuple\n",
    "    column_map.setdefault(column_values, []).append(col)\n",
    "\n",
    "# Step 2: Identify columns with duplicate data\n",
    "duplicate_columns = {k: v for k, v in column_map.items() if len(v) > 1}\n",
    "\n",
    "# Step 3: Keep only one column from each group\n",
    "columns_to_drop = [cols[1:] for cols in duplicate_columns.values()]  # Get all but the first column in each group\n",
    "columns_to_drop = [col for group in columns_to_drop for col in group]  # Flatten the list of lists\n",
    "\n",
    "# Drop duplicate columns\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qty_._url', 'qty_-_url', 'qty_/_url', 'qty_tld_url', 'length_url',\n",
       "       'qty_._domain', 'qty_-_domain', 'qty_vowels_domain', 'domain_length',\n",
       "       'qty_._directory', 'qty_-_directory', 'qty_/_directory',\n",
       "       'directory_length', 'qty_-_file', 'file_length', 'params_length',\n",
       "       'qty_params', 'path_level', 'num_numeric_chars', 'no_https',\n",
       "       'num_sensitive_words', 'prefix_suffix_in_domain', 'script_files_ratio',\n",
       "       'css_files_ratio', 'image_files_ratio', 'anchor_files_ratio',\n",
       "       'empty_anchor_ratio', 'null_hyperlink_ratio', 'total_hyperlinks',\n",
       "       'internal_hyperlink_ratio', 'external_hyperlink_ratio',\n",
       "       'external_to_internal_ratio', 'total_forms', 'suspicious_form_ratio',\n",
       "       'PctExtHyperlinks', 'PctExtResourceUrls',\n",
       "       'PctNullSelfRedirectHyperlinks', 'SubmitInfoToEmail', 'IframeOrFrame',\n",
       "       'ExtMetaScriptLinkRT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "X = df.drop(columns=['rec_id', 'phishing'])\n",
    "y = df['phishing']\n",
    "\n",
    "# Apply SelectKBest with mutual information\n",
    "k = 40  # Number of top features to select\n",
    "selector = SelectKBest(mutual_info_classif, k=k)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "\n",
    "# Create a DataFrame with the selected features\n",
    "X_selected = pd.DataFrame(X_new, columns=selected_features)\n",
    "\n",
    "# Display the selected features\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 173)\n",
      "(80000, 41)\n",
      "linear qty_-_domain [0. 3. 4. 5.]\n",
      "linear qty_-_file [ 0. 10. 11. 15.]\n",
      "linear params_length [  0.       157.       208.       462.000004 462.004   ]\n",
      "linear qty_params [ 0.  4.  6. 10.]\n",
      "linear suspicious_form_ratio [0.  0.5 1. ]\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(filepath, n_bins=4):\n",
    "    \"\"\"\n",
    "    Loads the dataset and converts features into itemsets for association rule mining.\n",
    "    Binary features are converted to <feature_name>_1 or <feature_name>_0.\n",
    "    Numerical features are binned into ranges and converted to <feature_name>_<start_value>_<end_value>.\n",
    "    Assumes the column 'phishing' is the target class.\n",
    "    \n",
    "    Parameters:\n",
    "        filepath (str): Path to the CSV file.\n",
    "        n_bins (int): Number of bins for numerical features.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame where rows represent itemsets.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(df.shape)\n",
    "    df = df[selected_features.tolist() + ['phishing']]\n",
    "    df = df.iloc[:, :]  # For testing on a smaller subset\n",
    "    print(df.shape)\n",
    "\n",
    "    itemsets = []\n",
    "\n",
    "    bins_dict = {}\n",
    "    for col in df.columns:\n",
    "        if col!='phishing' and (df[col].dtype in ['int64', 'float64']) and df[col].nunique() > 2:\n",
    "            df[col] = df[col].clip(lower=df[col].min(), \n",
    "                                               upper=df[col].quantile(0.999))\n",
    "            if df[col].nunique() <= 2:\n",
    "                continue\n",
    "            bins = pd.qcut(df[col], q=n_bins, duplicates='drop', retbins=True)[1]\n",
    "            if len(bins) < 3:\n",
    "                bins = pd.cut(df[col], \n",
    "                              bins=[df[col].min(), df[col].quantile(0.01), df[col].quantile(0.05), df[col].quantile(0.1), \n",
    "                                    df[col].quantile(0.2),df[col].quantile(0.4), df[col].quantile(0.99), \n",
    "                                    df[col].quantile(0.995), df[col].quantile(0.999), df[col].max()],\n",
    "                                       duplicates='drop', retbins=True)[1]\n",
    "                if len(bins) == 2:\n",
    "                    bins = np.insert(bins, 1, (bins[0]+bins[1])/2)\n",
    "                print('linear', col, bins)\n",
    "            bin_labels = [f\"{col}_{round(bins[i], 2)}_{round(bins[i+1], 2)}\" for i in range(len(bins) - 1)]\n",
    "            bins_dict[col] = {'bins': bins, 'labels': bin_labels}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if index % 1000 == 0:\n",
    "            print(index)\n",
    "        itemset = []\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if df[col].dtype in ['int64', 'float64'] and df[col].nunique() > 2:\n",
    "                # Numerical feature: binning into ranges\n",
    "                bins = bins_dict[col]['bins']\n",
    "                bin_labels = bins_dict[col]['labels']\n",
    "                bin_idx = np.digitize(row[col], bins) - 1\n",
    "                bin_idx = min(bin_idx, len(bin_labels) - 1)  # Ensure index is within range\n",
    "                itemset.append(bin_labels[bin_idx])\n",
    "            else:\n",
    "                # Binary/categorical feature: encode as <feature_name>_value\n",
    "                itemset.append(f\"{col}_{int(row[col])}\")\n",
    "        \n",
    "        itemsets.append(itemset)\n",
    "\n",
    "    # Convert itemsets into a DataFrame for analysis\n",
    "    transactions_df = pd.DataFrame({'itemsets': itemsets})\n",
    "    return transactions_df\n",
    "\n",
    "# Load and preprocess data\n",
    "df = preprocess_data(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('pattern_mining/preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            itemsets\n",
       "0  [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "1  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "2  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "3  [qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...\n",
       "4  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>[qty_._url_0.0_2.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                itemsets\n",
       "0      [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "1      [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "2      [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "3      [qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...\n",
       "4      [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "...                                                  ...\n",
       "79995  [qty_._url_0.0_2.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "79996  [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "79997  [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "79998  [qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...\n",
       "79999  [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "\n",
       "[80000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "df = pd.read_csv('pattern_mining/preprocessed.csv', index_col=0)\n",
    "df['itemsets'] = df['itemsets'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           itemsets\n",
       "0           0  [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "1           1  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "2           2  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "3           3  [qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...\n",
       "4           4  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 58)\n",
      "done\n",
      "(50000, 67)\n",
      "done\n",
      "Frequent itemsets including phishing_0:\n",
      "        support                                           itemsets\n",
      "0       0.99842                             (qty_-_domain_0.0_3.0)\n",
      "1       0.98266                              (qty_-_file_0.0_10.0)\n",
      "2       0.93886                        (prefix_suffix_in_domain_0)\n",
      "3       0.91872                            (num_sensitive_words_0)\n",
      "4       0.88166                                       (no_https_0)\n",
      "...         ...                                                ...\n",
      "133651  0.05136  (ExtMetaScriptLinkRT_0.15_0.34, image_files_ra...\n",
      "133652  0.05798  (params_length_0.0_157.0, ExtMetaScriptLinkRT_...\n",
      "133653  0.05130  (ExtMetaScriptLinkRT_0.15_0.34, image_files_ra...\n",
      "133654  0.05130  (params_length_0.0_157.0, ExtMetaScriptLinkRT_...\n",
      "133655  0.05126  (ExtMetaScriptLinkRT_0.15_0.34, qty_tld_url_3....\n",
      "\n",
      "[133656 rows x 2 columns]\n",
      "(30000, 63)\n",
      "done\n",
      "(30000, 63)\n",
      "done\n",
      "Frequent itemsets including phishing_1:\n",
      "         support                                           itemsets\n",
      "0       0.999333                              (qty_-_file_0.0_10.0)\n",
      "1       0.984033                              (SubmitInfoToEmail_0)\n",
      "2       0.952667                          (params_length_0.0_157.0)\n",
      "3       0.879833                                  (IframeOrFrame_0)\n",
      "4       0.784033                      (PctExtResourceUrls_0.49_1.0)\n",
      "...          ...                                                ...\n",
      "166466  0.056667  (qty_vowels_domain_4.0_5.0, qty_-_domain_0.0_3...\n",
      "166467  0.054267  (qty_vowels_domain_4.0_5.0, qty_-_domain_0.0_3...\n",
      "166468  0.054000  (qty_vowels_domain_4.0_5.0, qty_-_directory_0....\n",
      "166469  0.053000  (no_https_0, qty_vowels_domain_4.0_5.0, qty_-_...\n",
      "166470  0.050067  (qty_vowels_domain_4.0_5.0, qty_-_domain_0.0_3...\n",
      "\n",
      "[166471 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def mine_frequent_itemsets(df_itemsets, label, min_support=0.01):\n",
    "    \"\"\"\n",
    "    Mines frequent patterns for transactions containing 'phishing_1',\n",
    "    and appends 'phishing_1' to all resulting frequent itemsets.\n",
    "    \n",
    "    Parameters:\n",
    "        df_itemsets (pd.DataFrame): DataFrame with a column 'itemsets' containing lists of items.\n",
    "        min_support (float): Minimum support threshold for frequent itemsets.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Frequent itemsets including 'phishing_1' with their support values.\n",
    "    \"\"\"\n",
    "    # Filter transactions to only include those containing 'phishing_1'\n",
    "\n",
    "    random.seed = 42\n",
    "    f = list(selected_features)\n",
    "    random.shuffle(f)\n",
    "    features = [tuple(f[:20]), tuple(f[20:])]\n",
    "\n",
    "    all_frequent_itemsets = []\n",
    "    \n",
    "    for feature_set in features:\n",
    "    # Remove 'phishing_1' from each transaction (to avoid redundancy in mining)\n",
    "        transactions = df_itemsets['itemsets']\n",
    "        filtered_transactions = [t for t in transactions if label in t]\n",
    "        filtered_transactions = [\n",
    "            [item for item in t if (item != label and item.startswith(feature_set))] for t in filtered_transactions\n",
    "        ]\n",
    "        \n",
    "        # Convert transactions into a one-hot encoded DataFrame\n",
    "        te = TransactionEncoder()\n",
    "        one_hot = te.fit_transform(filtered_transactions)\n",
    "        one_hot_df = pd.DataFrame(one_hot, columns=te.columns_)\n",
    "        print(one_hot_df.shape)\n",
    "        \n",
    "        # Mine frequent patterns from filtered transactions\n",
    "        frequent_itemsets = fpgrowth(one_hot_df, min_support=min_support, use_colnames=True, max_len=5)\n",
    "        # frequent_itemsets = apriori(one_hot_df, min_support=min_support, use_colnames=True)\n",
    "        \n",
    "        # Append 'phishing_1' to all itemsets\n",
    "        # frequent_itemsets['itemsets'] = frequent_itemsets['itemsets'].apply(lambda x: x | {label})\n",
    "        all_frequent_itemsets.append(frequent_itemsets)\n",
    "        print('done')\n",
    "        \n",
    "    combined_frequent_itemsets = pd.concat(all_frequent_itemsets, ignore_index=True)\n",
    "    print(f\"Frequent itemsets including {label}:\")\n",
    "    print(combined_frequent_itemsets)\n",
    "    \n",
    "    return combined_frequent_itemsets\n",
    "\n",
    "\n",
    "min_support = 0.05  # Adjust minimum support threshold\n",
    "# Mine frequent itemsets\n",
    "frequent_itemset_0 = mine_frequent_itemsets(df, 'phishing_0', min_support)\n",
    "frequent_itemset_1 = mine_frequent_itemsets(df, 'phishing_1', min_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6399\n",
      "        support                                           itemsets\n",
      "2058    0.75776  (qty_@_params_0, qty___file_0.0_3.0, prefix_su...\n",
      "3082    0.78816  (qty_@_params_0, qty_tld_url_3.0_8.0, qty___fi...\n",
      "3594    0.74102  (qty_@_params_0, qty_tld_url_3.0_8.0, qty___fi...\n",
      "3850    0.71328  (qty_@_params_0, qty_tld_url_3.0_8.0, prefix_s...\n",
      "3978    0.70116  (qty_@_params_0, qty_tld_url_3.0_8.0, qty___fi...\n",
      "...         ...                                                ...\n",
      "148731  0.52510  (qty_&_params_0.0_3.0, qty_=_url_0.0_4.0, qty_...\n",
      "148732  0.52510  (qty_&_params_0.0_3.0, qty_=_url_0.0_4.0, qty_...\n",
      "148733  0.52510  (qty_&_params_0.0_3.0, qty_=_url_0.0_4.0, qty_...\n",
      "148734  0.52510  (qty_&_params_0.0_3.0, qty_=_url_0.0_4.0, qty_...\n",
      "148735  0.52510  (qty_&_params_0.0_3.0, qty_=_url_0.0_4.0, qty_...\n",
      "\n",
      "[6399 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "filtered = frequent_itemset_0[frequent_itemset_0['itemsets'].apply(len) > 10]\n",
    "print(len(filtered))\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_association_rules(df, frequent_itemsets, label, min_threshold=0.8):\n",
    "    # Convert transactions into a one-hot encoded DataFrame\n",
    "    transactions = df['itemsets']\n",
    "    te = TransactionEncoder()\n",
    "    one_hot = te.fit_transform(transactions)\n",
    "    one_hot_df = pd.DataFrame(one_hot, columns=te.columns_)\n",
    "\n",
    "    # Calculate support for the consequent (label)\n",
    "    total_transactions = len(one_hot_df)\n",
    "    consequent_support = one_hot_df[label].sum() / total_transactions\n",
    "\n",
    "    # Initialize results\n",
    "    results = []\n",
    "    c = 0\n",
    "    for itemset in frequent_itemsets:\n",
    "        c+=1\n",
    "        if c%1000==0:\n",
    "            print(c)\n",
    "        # Convert itemset to list\n",
    "        itemset_list = list(itemset)\n",
    "\n",
    "        # Calculate support of antecedent\n",
    "        antecedent_support = np.all(one_hot_df[itemset_list].values, axis=1).sum() / total_transactions\n",
    "\n",
    "        # Calculate support of (antecedent ∪ label)\n",
    "        union_support = np.all(one_hot_df[itemset_list + [label]].values, axis=1).sum() / total_transactions\n",
    "\n",
    "        # Calculate confidence\n",
    "        confidence = union_support / antecedent_support if antecedent_support > 0 else 0\n",
    "\n",
    "        # Calculate lift\n",
    "        lift = confidence / consequent_support if consequent_support > 0 else 0\n",
    "\n",
    "        if confidence > min_threshold:\n",
    "            results.append({\n",
    "                \"Itemset\": itemset,\n",
    "                \"Antecedent Support\": antecedent_support,\n",
    "                \"Union Support\": union_support,\n",
    "                \"Confidence\": confidence,\n",
    "                \"Lift\": lift\n",
    "            })\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Itemset</th>\n",
       "      <th>Antecedent Support</th>\n",
       "      <th>Union Support</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(external_hyperlink_ratio_0.05_0.17)</td>\n",
       "      <td>0.251075</td>\n",
       "      <td>0.209300</td>\n",
       "      <td>0.833615</td>\n",
       "      <td>1.333785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(PctExtHyperlinks_0.21_0.92)</td>\n",
       "      <td>0.250038</td>\n",
       "      <td>0.228013</td>\n",
       "      <td>0.911913</td>\n",
       "      <td>1.459061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(file_length_13.0_148.0)</td>\n",
       "      <td>0.260663</td>\n",
       "      <td>0.222562</td>\n",
       "      <td>0.853834</td>\n",
       "      <td>1.366134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(IframeOrFrame_1)</td>\n",
       "      <td>0.252775</td>\n",
       "      <td>0.207712</td>\n",
       "      <td>0.821729</td>\n",
       "      <td>1.314766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(internal_hyperlink_ratio_0.62_0.8)</td>\n",
       "      <td>0.250075</td>\n",
       "      <td>0.202725</td>\n",
       "      <td>0.810657</td>\n",
       "      <td>1.297051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67553</th>\n",
       "      <td>(qty_-_directory_2.0_18.0, qty_-_url_2.0_19.0,...</td>\n",
       "      <td>0.042150</td>\n",
       "      <td>0.037838</td>\n",
       "      <td>0.897687</td>\n",
       "      <td>1.436299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67554</th>\n",
       "      <td>(qty_-_directory_2.0_18.0, qty_tld_url_3.0_8.0...</td>\n",
       "      <td>0.042075</td>\n",
       "      <td>0.037838</td>\n",
       "      <td>0.899287</td>\n",
       "      <td>1.438859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67555</th>\n",
       "      <td>(anchor_files_ratio_0.51_0.69, image_files_rat...</td>\n",
       "      <td>0.045637</td>\n",
       "      <td>0.037175</td>\n",
       "      <td>0.814571</td>\n",
       "      <td>1.303314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67556</th>\n",
       "      <td>(qty_._domain_2.0_6.0, qty_tld_url_3.0_8.0, pa...</td>\n",
       "      <td>0.045538</td>\n",
       "      <td>0.037112</td>\n",
       "      <td>0.814988</td>\n",
       "      <td>1.303980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67557</th>\n",
       "      <td>(qty_._domain_2.0_6.0, qty_tld_url_3.0_8.0, an...</td>\n",
       "      <td>0.045050</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.812431</td>\n",
       "      <td>1.299889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67558 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Itemset  Antecedent Support  \\\n",
       "0                   (external_hyperlink_ratio_0.05_0.17)            0.251075   \n",
       "1                           (PctExtHyperlinks_0.21_0.92)            0.250038   \n",
       "2                               (file_length_13.0_148.0)            0.260663   \n",
       "3                                      (IframeOrFrame_1)            0.252775   \n",
       "4                    (internal_hyperlink_ratio_0.62_0.8)            0.250075   \n",
       "...                                                  ...                 ...   \n",
       "67553  (qty_-_directory_2.0_18.0, qty_-_url_2.0_19.0,...            0.042150   \n",
       "67554  (qty_-_directory_2.0_18.0, qty_tld_url_3.0_8.0...            0.042075   \n",
       "67555  (anchor_files_ratio_0.51_0.69, image_files_rat...            0.045637   \n",
       "67556  (qty_._domain_2.0_6.0, qty_tld_url_3.0_8.0, pa...            0.045538   \n",
       "67557  (qty_._domain_2.0_6.0, qty_tld_url_3.0_8.0, an...            0.045050   \n",
       "\n",
       "       Union Support  Confidence      Lift  \n",
       "0           0.209300    0.833615  1.333785  \n",
       "1           0.228013    0.911913  1.459061  \n",
       "2           0.222562    0.853834  1.366134  \n",
       "3           0.207712    0.821729  1.314766  \n",
       "4           0.202725    0.810657  1.297051  \n",
       "...              ...         ...       ...  \n",
       "67553       0.037838    0.897687  1.436299  \n",
       "67554       0.037838    0.899287  1.438859  \n",
       "67555       0.037175    0.814571  1.303314  \n",
       "67556       0.037112    0.814988  1.303980  \n",
       "67557       0.036600    0.812431  1.299889  \n",
       "\n",
       "[67558 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_df = generate_association_rules(df, frequent_itemset_0['itemsets'], 'phishing_0')\n",
    "rules_df.to_csv('pattern_mining/rules_0_4.csv')\n",
    "rules_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999333</td>\n",
       "      <td>(qty_-_file_0.0_10.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.980867</td>\n",
       "      <td>(qty_params_0.0_4.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.980867</td>\n",
       "      <td>(qty_&amp;_params_0.0_3.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.978900</td>\n",
       "      <td>(qty_/_params_0.0_1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.978833</td>\n",
       "      <td>(qty___params_0.0_2.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114872</th>\n",
       "      <td>0.303267</td>\n",
       "      <td>(qty___file_0.0_3.0, num_numeric_chars_4.0_170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114873</th>\n",
       "      <td>0.302200</td>\n",
       "      <td>(qty___file_0.0_3.0, num_numeric_chars_4.0_170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114874</th>\n",
       "      <td>0.302200</td>\n",
       "      <td>(qty___file_0.0_3.0, num_numeric_chars_4.0_170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114875</th>\n",
       "      <td>0.300467</td>\n",
       "      <td>(qty_._params_0.0_2.0, num_numeric_chars_4.0_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114876</th>\n",
       "      <td>0.300300</td>\n",
       "      <td>(qty_=_directory_0.0_1.0, params_length_0.0_15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114877 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         support                                           itemsets\n",
       "0       0.999333                              (qty_-_file_0.0_10.0)\n",
       "1       0.980867                               (qty_params_0.0_4.0)\n",
       "2       0.980867                             (qty_&_params_0.0_3.0)\n",
       "3       0.978900                             (qty_/_params_0.0_1.0)\n",
       "4       0.978833                             (qty___params_0.0_2.0)\n",
       "...          ...                                                ...\n",
       "114872  0.303267  (qty___file_0.0_3.0, num_numeric_chars_4.0_170...\n",
       "114873  0.302200  (qty___file_0.0_3.0, num_numeric_chars_4.0_170...\n",
       "114874  0.302200  (qty___file_0.0_3.0, num_numeric_chars_4.0_170...\n",
       "114875  0.300467  (qty_._params_0.0_2.0, num_numeric_chars_4.0_1...\n",
       "114876  0.300300  (qty_=_directory_0.0_1.0, params_length_0.0_15...\n",
       "\n",
       "[114877 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Itemset</th>\n",
       "      <th>Antecedent Support</th>\n",
       "      <th>Union Support</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(total_hyperlinks_0.0_16.0, total_forms_1.0_2.0)</td>\n",
       "      <td>0.088725</td>\n",
       "      <td>0.076088</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>2.286841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(total_hyperlinks_0.0_16.0, total_forms_1.0_2....</td>\n",
       "      <td>0.088637</td>\n",
       "      <td>0.076088</td>\n",
       "      <td>0.858412</td>\n",
       "      <td>2.289099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(total_hyperlinks_0.0_16.0, total_forms_1.0_2....</td>\n",
       "      <td>0.087950</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.858442</td>\n",
       "      <td>2.289179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(total_hyperlinks_0.0_16.0, total_forms_1.0_2....</td>\n",
       "      <td>0.086087</td>\n",
       "      <td>0.073650</td>\n",
       "      <td>0.855525</td>\n",
       "      <td>2.281400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(params_length_0.0_157.0, total_hyperlinks_0.0...</td>\n",
       "      <td>0.082988</td>\n",
       "      <td>0.070587</td>\n",
       "      <td>0.850580</td>\n",
       "      <td>2.268213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29636</th>\n",
       "      <td>(empty_anchor_ratio_0.0_0.01, suspicious_form_...</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.018988</td>\n",
       "      <td>0.811432</td>\n",
       "      <td>2.163818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29637</th>\n",
       "      <td>(suspicious_form_ratio_0.0_0.5, qty_._url_3.0_...</td>\n",
       "      <td>0.023537</td>\n",
       "      <td>0.018863</td>\n",
       "      <td>0.801381</td>\n",
       "      <td>2.137015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29638</th>\n",
       "      <td>(qty_._domain_1.0_2.0, external_hyperlink_rati...</td>\n",
       "      <td>0.024450</td>\n",
       "      <td>0.020075</td>\n",
       "      <td>0.821063</td>\n",
       "      <td>2.189502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29639</th>\n",
       "      <td>(num_numeric_chars_4.0_170.01, external_hyperl...</td>\n",
       "      <td>0.024850</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.800805</td>\n",
       "      <td>2.135480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29640</th>\n",
       "      <td>(domain_length_23.0_74.0, qty_-_directory_0.0_...</td>\n",
       "      <td>0.021925</td>\n",
       "      <td>0.019213</td>\n",
       "      <td>0.876283</td>\n",
       "      <td>2.336754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29641 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Itemset  Antecedent Support  \\\n",
       "0       (total_hyperlinks_0.0_16.0, total_forms_1.0_2.0)            0.088725   \n",
       "1      (total_hyperlinks_0.0_16.0, total_forms_1.0_2....            0.088637   \n",
       "2      (total_hyperlinks_0.0_16.0, total_forms_1.0_2....            0.087950   \n",
       "3      (total_hyperlinks_0.0_16.0, total_forms_1.0_2....            0.086087   \n",
       "4      (params_length_0.0_157.0, total_hyperlinks_0.0...            0.082988   \n",
       "...                                                  ...                 ...   \n",
       "29636  (empty_anchor_ratio_0.0_0.01, suspicious_form_...            0.023400   \n",
       "29637  (suspicious_form_ratio_0.0_0.5, qty_._url_3.0_...            0.023537   \n",
       "29638  (qty_._domain_1.0_2.0, external_hyperlink_rati...            0.024450   \n",
       "29639  (num_numeric_chars_4.0_170.01, external_hyperl...            0.024850   \n",
       "29640  (domain_length_23.0_74.0, qty_-_directory_0.0_...            0.021925   \n",
       "\n",
       "       Union Support  Confidence      Lift  \n",
       "0           0.076088    0.857566  2.286841  \n",
       "1           0.076088    0.858412  2.289099  \n",
       "2           0.075500    0.858442  2.289179  \n",
       "3           0.073650    0.855525  2.281400  \n",
       "4           0.070587    0.850580  2.268213  \n",
       "...              ...         ...       ...  \n",
       "29636       0.018988    0.811432  2.163818  \n",
       "29637       0.018863    0.801381  2.137015  \n",
       "29638       0.020075    0.821063  2.189502  \n",
       "29639       0.019900    0.800805  2.135480  \n",
       "29640       0.019213    0.876283  2.336754  \n",
       "\n",
       "[29641 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_df = generate_association_rules(df, frequent_itemset_1['itemsets'], 'phishing_1')\n",
    "rules_df.to_csv('pattern_mining/rules_1_4.csv')\n",
    "rules_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
