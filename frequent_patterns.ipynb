{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filepath = \"features/url_features.csv\"  # Replace with your dataset file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate columns (with different names):\n",
      "Columns ['qty_._url', 'num_dots'] have identical values.\n",
      "Columns ['qty_-_url', 'num_dash'] have identical values.\n",
      "Columns ['qty___url', 'num_underscore'] have identical values.\n",
      "Columns ['qty_&_url', 'num_ampersand'] have identical values.\n",
      "Columns ['qty_#_url', 'num_hash'] have identical values.\n",
      "Columns ['qty_%_url', 'num_percent'] have identical values.\n",
      "Columns ['length_url', 'url_length'] have identical values.\n",
      "Columns ['qty_._domain', 'subdomain_level', 'subdomain_count'] have identical values.\n",
      "Columns ['qty_-_domain', 'num_dash_in_hostname'] have identical values.\n",
      "Columns ['domain_length', 'hostname_length'] have identical values.\n",
      "Columns ['domain_in_ip', 'ip_address', 'ip_address_in_url'] have identical values.\n",
      "Columns ['directory_length', 'path_length'] have identical values.\n",
      "Columns ['params_length', 'query_length'] have identical values.\n",
      "Columns ['qty_params', 'num_query_components'] have identical values.\n",
      "Columns ['at_symbol', 'at_symbol_in_url'] have identical values.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(filepath)\n",
    "df = df.loc[:, df.nunique() > 1]\n",
    "\n",
    "# Step 1: Create a dictionary to store column data as tuples\n",
    "column_map = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    column_values = tuple(df[col])  # Convert column values to a tuple\n",
    "    column_map.setdefault(column_values, []).append(col)\n",
    "\n",
    "# Step 2: Identify columns with duplicate data but different names\n",
    "duplicate_columns = {k: v for k, v in column_map.items() if len(v) > 1}\n",
    "\n",
    "# Display results\n",
    "print(\"Duplicate columns (with different names):\")\n",
    "for values, columns in duplicate_columns.items():\n",
    "    print(f\"Columns {columns} have identical values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 144)\n",
      "(80000, 107)\n",
      "(80000, 90)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(filepath)\n",
    "print(df.shape)\n",
    "df = df.loc[:, df.nunique() > 1]\n",
    "print(df.shape)\n",
    "\n",
    "column_map = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    column_values = tuple(df[col])  # Convert column values to a tuple\n",
    "    column_map.setdefault(column_values, []).append(col)\n",
    "\n",
    "# Step 2: Identify columns with duplicate data\n",
    "duplicate_columns = {k: v for k, v in column_map.items() if len(v) > 1}\n",
    "\n",
    "# Step 3: Keep only one column from each group\n",
    "columns_to_drop = [cols[1:] for cols in duplicate_columns.values()]  # Get all but the first column in each group\n",
    "columns_to_drop = [col for group in columns_to_drop for col in group]  # Flatten the list of lists\n",
    "\n",
    "# Drop duplicate columns\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qty_._url', 'qty_-_url', 'qty_/_url', 'qty_?_url', 'qty_=_url',\n",
       "       'qty_@_url', 'qty_&_url', 'qty_tld_url', 'length_url', 'email_in_url',\n",
       "       'qty_._domain', 'qty_-_domain', 'qty_vowels_domain', 'domain_length',\n",
       "       'qty_._directory', 'qty_-_directory', 'qty_/_directory',\n",
       "       'qty_=_directory', 'directory_length', 'qty_._file', 'qty_-_file',\n",
       "       'qty___file', 'file_length', 'qty_._params', 'qty_-_params',\n",
       "       'qty___params', 'qty_=_params', 'qty_@_params', 'qty_&_params',\n",
       "       'params_length', 'qty_params', 'path_level', 'at_symbol',\n",
       "       'num_numeric_chars', 'no_https', 'random_string',\n",
       "       'domain_in_subdomains', 'domain_in_paths', 'num_sensitive_words',\n",
       "       'prefix_suffix_in_domain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "X = df.drop(columns=['rec_id', 'phishing'])\n",
    "y = df['phishing']\n",
    "\n",
    "# Apply SelectKBest with mutual information\n",
    "k = 40  # Number of top features to select\n",
    "selector = SelectKBest(mutual_info_classif, k=k)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "\n",
    "# Create a DataFrame with the selected features\n",
    "X_selected = pd.DataFrame(X_new, columns=selected_features)\n",
    "\n",
    "# Display the selected features\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 144)\n",
      "(80000, 51)\n",
      "linear qty_?_url [0. 1. 2.]\n",
      "linear qty_=_url [ 0.  4.  7. 11.]\n",
      "linear qty_&_url [ 0.  3.  6. 10.]\n",
      "linear qty_,_url [0. 2. 4.]\n",
      "linear qty_-_domain [0. 3. 4. 5.]\n",
      "linear qty___directory [0. 4. 5. 9.]\n",
      "linear qty_=_directory [0. 1. 2.]\n",
      "linear qty_,_directory [0. 2. 4.]\n",
      "linear qty_-_file [ 0. 10. 11. 15.]\n",
      "linear qty___file [0. 3. 4. 8.]\n",
      "linear qty_,_file [0. 2. 4.]\n",
      "linear qty_%_file [0. 1. 6.]\n",
      "linear qty_._params [ 0.  2.  4. 21.]\n",
      "linear qty_-_params [0. 2. 4. 9.]\n",
      "linear qty___params [ 0.  2.  3. 18.]\n",
      "linear qty_=_params [ 0.  4.  7. 11.]\n",
      "linear qty_&_params [0. 3. 5. 9.]\n",
      "linear params_length [  0.       157.       208.       462.000004 462.004   ]\n",
      "linear qty_params [ 0.  4.  6. 10.]\n",
      "linear domain_in_subdomains [0. 1. 2.]\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(filepath, n_bins=4):\n",
    "    \"\"\"\n",
    "    Loads the dataset and converts features into itemsets for association rule mining.\n",
    "    Binary features are converted to <feature_name>_1 or <feature_name>_0.\n",
    "    Numerical features are binned into ranges and converted to <feature_name>_<start_value>_<end_value>.\n",
    "    Assumes the column 'phishing' is the target class.\n",
    "    \n",
    "    Parameters:\n",
    "        filepath (str): Path to the CSV file.\n",
    "        n_bins (int): Number of bins for numerical features.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame where rows represent itemsets.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(df.shape)\n",
    "    df = df[selected_features.tolist() + ['phishing']]\n",
    "    df = df.iloc[:, :]  # For testing on a smaller subset\n",
    "    print(df.shape)\n",
    "\n",
    "    itemsets = []\n",
    "\n",
    "    bins_dict = {}\n",
    "    for col in df.columns:\n",
    "        if col!='phishing' and (df[col].dtype in ['int64', 'float64']) and df[col].nunique() > 2:\n",
    "            df[col] = df[col].clip(lower=df[col].min(), \n",
    "                                               upper=df[col].quantile(0.999))\n",
    "            if df[col].nunique() <= 2:\n",
    "                continue\n",
    "            bins = pd.qcut(df[col], q=n_bins, duplicates='drop', retbins=True)[1]\n",
    "            if len(bins) < 3:\n",
    "                bins = pd.cut(df[col], \n",
    "                              bins=[df[col].min(), df[col].quantile(0.01), df[col].quantile(0.05), df[col].quantile(0.1), \n",
    "                                    df[col].quantile(0.2),df[col].quantile(0.4), df[col].quantile(0.99), \n",
    "                                    df[col].quantile(0.995), df[col].quantile(0.999), df[col].max()],\n",
    "                                       duplicates='drop', retbins=True)[1]\n",
    "                if len(bins) == 2:\n",
    "                    bins = np.insert(bins, 1, (bins[0]+bins[1])/2)\n",
    "                print('linear', col, bins)\n",
    "            bin_labels = [f\"{col}_{round(bins[i], 2)}_{round(bins[i+1], 2)}\" for i in range(len(bins) - 1)]\n",
    "            bins_dict[col] = {'bins': bins, 'labels': bin_labels}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if index % 1000 == 0:\n",
    "            print(index)\n",
    "        itemset = []\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if df[col].dtype in ['int64', 'float64'] and df[col].nunique() > 2:\n",
    "                # Numerical feature: binning into ranges\n",
    "                bins = bins_dict[col]['bins']\n",
    "                bin_labels = bins_dict[col]['labels']\n",
    "                bin_idx = np.digitize(row[col], bins) - 1\n",
    "                bin_idx = min(bin_idx, len(bin_labels) - 1)  # Ensure index is within range\n",
    "                itemset.append(bin_labels[bin_idx])\n",
    "            else:\n",
    "                # Binary/categorical feature: encode as <feature_name>_value\n",
    "                itemset.append(f\"{col}_{int(row[col])}\")\n",
    "        \n",
    "        itemsets.append(itemset)\n",
    "\n",
    "    # Convert itemsets into a DataFrame for analysis\n",
    "    transactions_df = pd.DataFrame({'itemsets': itemsets})\n",
    "    return transactions_df\n",
    "\n",
    "# Load and preprocess data\n",
    "df = preprocess_data(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('pattern_mining/preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            itemsets\n",
       "0  [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "1  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "2  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "3  [qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...\n",
       "4  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>[qty_._url_0.0_2.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                itemsets\n",
       "0      [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "1      [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "2      [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "3      [qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...\n",
       "4      [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "...                                                  ...\n",
       "79995  [qty_._url_0.0_2.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "79996  [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "79997  [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "79998  [qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...\n",
       "79999  [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "\n",
       "[80000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "df = pd.read_csv('pattern_mining/preprocessed.csv')\n",
    "df['itemsets'] = df['itemsets'].apply(ast.literal_eval)\n",
    "df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           itemsets\n",
       "0           0  [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "1           1  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "2           2  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "3           3  [qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...\n",
       "4           4  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 55)\n",
      "done\n",
      "(50000, 55)\n",
      "done\n",
      "Frequent itemsets including phishing_0:\n",
      "        support                                           itemsets\n",
      "0       0.99998                                   (qty_@_params_0)\n",
      "1       0.99990                                   (email_in_url_0)\n",
      "2       0.99948                                      (qty_@_url_0)\n",
      "3       0.99948                                      (at_symbol_0)\n",
      "4       0.99842                             (qty_-_domain_0.0_3.0)\n",
      "...         ...                                                ...\n",
      "122886  0.10024  (qty_=_params_0.0_4.0, qty_vowels_domain_0.0_4...\n",
      "122887  0.10024  (qty_vowels_domain_0.0_4.0, qty_&_url_0.0_3.0,...\n",
      "122888  0.10024  (qty_vowels_domain_0.0_4.0, qty_tld_url_3.0_8....\n",
      "122889  0.10024  (qty_vowels_domain_0.0_4.0, qty_params_0.0_4.0...\n",
      "122890  0.10022  (domain_in_paths_0, qty_vowels_domain_0.0_4.0,...\n",
      "\n",
      "[122891 rows x 2 columns]\n",
      "(30000, 58)\n",
      "done\n",
      "(30000, 53)\n",
      "done\n",
      "Frequent itemsets including phishing_1:\n",
      "         support                                           itemsets\n",
      "0       0.996467                               (qty___file_0.0_3.0)\n",
      "1       0.980867                               (qty_params_0.0_4.0)\n",
      "2       0.980867                             (qty_&_params_0.0_3.0)\n",
      "3       0.977900                                   (email_in_url_0)\n",
      "4       0.976933                             (qty_._params_0.0_2.0)\n",
      "...          ...                                                ...\n",
      "115296  0.100933  (domain_length_15.0_18.0, qty_?_url_0.0_1.0, q...\n",
      "115297  0.101000  (domain_length_15.0_18.0, qty_?_url_0.0_1.0, q...\n",
      "115298  0.100933  (domain_length_15.0_18.0, qty_?_url_0.0_1.0, q...\n",
      "115299  0.100933  (domain_length_15.0_18.0, qty_?_url_0.0_1.0, q...\n",
      "115300  0.100933  (domain_length_15.0_18.0, qty_?_url_0.0_1.0, q...\n",
      "\n",
      "[115301 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def mine_frequent_itemsets(df_itemsets, label, min_support=0.01):\n",
    "    \"\"\"\n",
    "    Mines frequent patterns for transactions containing 'phishing_1',\n",
    "    and appends 'phishing_1' to all resulting frequent itemsets.\n",
    "    \n",
    "    Parameters:\n",
    "        df_itemsets (pd.DataFrame): DataFrame with a column 'itemsets' containing lists of items.\n",
    "        min_support (float): Minimum support threshold for frequent itemsets.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Frequent itemsets including 'phishing_1' with their support values.\n",
    "    \"\"\"\n",
    "    # Filter transactions to only include those containing 'phishing_1'\n",
    "\n",
    "    random.seed = 42\n",
    "    f = list(selected_features)\n",
    "    random.shuffle(f)\n",
    "    features = [tuple(f[:20]), tuple(f[20:])]\n",
    "\n",
    "    all_frequent_itemsets = []\n",
    "    \n",
    "    for feature_set in features:\n",
    "    # Remove 'phishing_1' from each transaction (to avoid redundancy in mining)\n",
    "        transactions = df_itemsets['itemsets']\n",
    "        filtered_transactions = [t for t in transactions if label in t]\n",
    "        filtered_transactions = [\n",
    "            [item for item in t if (item != label and item.startswith(feature_set))] for t in filtered_transactions\n",
    "        ]\n",
    "        \n",
    "        # Convert transactions into a one-hot encoded DataFrame\n",
    "        te = TransactionEncoder()\n",
    "        one_hot = te.fit_transform(filtered_transactions)\n",
    "        one_hot_df = pd.DataFrame(one_hot, columns=te.columns_)\n",
    "        print(one_hot_df.shape)\n",
    "        \n",
    "        # Mine frequent patterns from filtered transactions\n",
    "        frequent_itemsets = fpgrowth(one_hot_df, min_support=min_support, use_colnames=True, max_len=5)\n",
    "        # frequent_itemsets = apriori(one_hot_df, min_support=min_support, use_colnames=True)\n",
    "        \n",
    "        # Append 'phishing_1' to all itemsets\n",
    "        # frequent_itemsets['itemsets'] = frequent_itemsets['itemsets'].apply(lambda x: x | {label})\n",
    "        all_frequent_itemsets.append(frequent_itemsets)\n",
    "        print('done')\n",
    "        \n",
    "    combined_frequent_itemsets = pd.concat(all_frequent_itemsets, ignore_index=True)\n",
    "    print(f\"Frequent itemsets including {label}:\")\n",
    "    print(combined_frequent_itemsets)\n",
    "    \n",
    "    return combined_frequent_itemsets\n",
    "\n",
    "\n",
    "min_support = 0.1  # Adjust minimum support threshold\n",
    "# Mine frequent itemsets\n",
    "frequent_itemset_0 = mine_frequent_itemsets(df, 'phishing_0', min_support)\n",
    "frequent_itemset_1 = mine_frequent_itemsets(df, 'phishing_1', min_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6399\n",
      "        support                                           itemsets\n",
      "2058    0.75776  (qty_@_params_0, qty___file_0.0_3.0, prefix_su...\n",
      "3082    0.78816  (qty_@_params_0, qty_tld_url_3.0_8.0, qty___fi...\n",
      "3594    0.74102  (qty_@_params_0, qty_tld_url_3.0_8.0, qty___fi...\n",
      "3850    0.71328  (qty_@_params_0, qty_tld_url_3.0_8.0, prefix_s...\n",
      "3978    0.70116  (qty_@_params_0, qty_tld_url_3.0_8.0, qty___fi...\n",
      "...         ...                                                ...\n",
      "148731  0.52510  (qty_&_params_0.0_3.0, qty_=_url_0.0_4.0, qty_...\n",
      "148732  0.52510  (qty_&_params_0.0_3.0, qty_=_url_0.0_4.0, qty_...\n",
      "148733  0.52510  (qty_&_params_0.0_3.0, qty_=_url_0.0_4.0, qty_...\n",
      "148734  0.52510  (qty_&_params_0.0_3.0, qty_=_url_0.0_4.0, qty_...\n",
      "148735  0.52510  (qty_&_params_0.0_3.0, qty_=_url_0.0_4.0, qty_...\n",
      "\n",
      "[6399 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "filtered = frequent_itemset_0[frequent_itemset_0['itemsets'].apply(len) > 10]\n",
    "print(len(filtered))\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_association_rules(df, frequent_itemsets, label, min_threshold=0.8):\n",
    "    # Convert transactions into a one-hot encoded DataFrame\n",
    "    transactions = df['itemsets']\n",
    "    te = TransactionEncoder()\n",
    "    one_hot = te.fit_transform(transactions)\n",
    "    one_hot_df = pd.DataFrame(one_hot, columns=te.columns_)\n",
    "\n",
    "    # Calculate support for the consequent (label)\n",
    "    total_transactions = len(one_hot_df)\n",
    "    consequent_support = one_hot_df[label].sum() / total_transactions\n",
    "\n",
    "    # Initialize results\n",
    "    results = []\n",
    "    c = 0\n",
    "    for itemset in frequent_itemsets:\n",
    "        c+=1\n",
    "        if c%1000==0:\n",
    "            print(c)\n",
    "        # Convert itemset to list\n",
    "        itemset_list = list(itemset)\n",
    "\n",
    "        # Calculate support of antecedent\n",
    "        antecedent_support = np.all(one_hot_df[itemset_list].values, axis=1).sum() / total_transactions\n",
    "\n",
    "        # Calculate support of (antecedent ∪ label)\n",
    "        union_support = np.all(one_hot_df[itemset_list + [label]].values, axis=1).sum() / total_transactions\n",
    "\n",
    "        # Calculate confidence\n",
    "        confidence = union_support / antecedent_support if antecedent_support > 0 else 0\n",
    "\n",
    "        # Calculate lift\n",
    "        lift = confidence / consequent_support if consequent_support > 0 else 0\n",
    "\n",
    "        if confidence > min_threshold:\n",
    "            results.append({\n",
    "                \"Itemset\": itemset,\n",
    "                \"Antecedent Support\": antecedent_support,\n",
    "                \"Union Support\": union_support,\n",
    "                \"Confidence\": confidence,\n",
    "                \"Lift\": lift\n",
    "            })\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Itemset</th>\n",
       "      <th>Antecedent Support</th>\n",
       "      <th>Union Support</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(file_length_13.0_148.0)</td>\n",
       "      <td>0.260663</td>\n",
       "      <td>0.222562</td>\n",
       "      <td>0.853834</td>\n",
       "      <td>1.366134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(no_https_0, qty_@_params_0, params_length_0.0...</td>\n",
       "      <td>0.645975</td>\n",
       "      <td>0.518038</td>\n",
       "      <td>0.801947</td>\n",
       "      <td>1.283115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(no_https_0, email_in_url_0, params_length_0.0...</td>\n",
       "      <td>0.645837</td>\n",
       "      <td>0.518025</td>\n",
       "      <td>0.802098</td>\n",
       "      <td>1.283357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(no_https_0, at_symbol_0, params_length_0.0_15...</td>\n",
       "      <td>0.644175</td>\n",
       "      <td>0.517763</td>\n",
       "      <td>0.803761</td>\n",
       "      <td>1.286017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(no_https_0, params_length_0.0_157.0, qty_@_ur...</td>\n",
       "      <td>0.644175</td>\n",
       "      <td>0.517763</td>\n",
       "      <td>0.803761</td>\n",
       "      <td>1.286017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32449</th>\n",
       "      <td>(qty_=_params_0.0_4.0, qty_vowels_domain_0.0_4...</td>\n",
       "      <td>0.073125</td>\n",
       "      <td>0.062650</td>\n",
       "      <td>0.856752</td>\n",
       "      <td>1.370803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32450</th>\n",
       "      <td>(qty_vowels_domain_0.0_4.0, qty_&amp;_url_0.0_3.0,...</td>\n",
       "      <td>0.073137</td>\n",
       "      <td>0.062650</td>\n",
       "      <td>0.856606</td>\n",
       "      <td>1.370569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32451</th>\n",
       "      <td>(qty_vowels_domain_0.0_4.0, qty_tld_url_3.0_8....</td>\n",
       "      <td>0.073137</td>\n",
       "      <td>0.062650</td>\n",
       "      <td>0.856606</td>\n",
       "      <td>1.370569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32452</th>\n",
       "      <td>(qty_vowels_domain_0.0_4.0, qty_params_0.0_4.0...</td>\n",
       "      <td>0.073137</td>\n",
       "      <td>0.062650</td>\n",
       "      <td>0.856606</td>\n",
       "      <td>1.370569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32453</th>\n",
       "      <td>(domain_in_paths_0, qty_vowels_domain_0.0_4.0,...</td>\n",
       "      <td>0.073137</td>\n",
       "      <td>0.062637</td>\n",
       "      <td>0.856435</td>\n",
       "      <td>1.370296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32454 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Itemset  Antecedent Support  \\\n",
       "0                               (file_length_13.0_148.0)            0.260663   \n",
       "1      (no_https_0, qty_@_params_0, params_length_0.0...            0.645975   \n",
       "2      (no_https_0, email_in_url_0, params_length_0.0...            0.645837   \n",
       "3      (no_https_0, at_symbol_0, params_length_0.0_15...            0.644175   \n",
       "4      (no_https_0, params_length_0.0_157.0, qty_@_ur...            0.644175   \n",
       "...                                                  ...                 ...   \n",
       "32449  (qty_=_params_0.0_4.0, qty_vowels_domain_0.0_4...            0.073125   \n",
       "32450  (qty_vowels_domain_0.0_4.0, qty_&_url_0.0_3.0,...            0.073137   \n",
       "32451  (qty_vowels_domain_0.0_4.0, qty_tld_url_3.0_8....            0.073137   \n",
       "32452  (qty_vowels_domain_0.0_4.0, qty_params_0.0_4.0...            0.073137   \n",
       "32453  (domain_in_paths_0, qty_vowels_domain_0.0_4.0,...            0.073137   \n",
       "\n",
       "       Union Support  Confidence      Lift  \n",
       "0           0.222562    0.853834  1.366134  \n",
       "1           0.518038    0.801947  1.283115  \n",
       "2           0.518025    0.802098  1.283357  \n",
       "3           0.517763    0.803761  1.286017  \n",
       "4           0.517763    0.803761  1.286017  \n",
       "...              ...         ...       ...  \n",
       "32449       0.062650    0.856752  1.370803  \n",
       "32450       0.062650    0.856606  1.370569  \n",
       "32451       0.062650    0.856606  1.370569  \n",
       "32452       0.062650    0.856606  1.370569  \n",
       "32453       0.062637    0.856435  1.370296  \n",
       "\n",
       "[32454 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_df = generate_association_rules(df, frequent_itemset_0['itemsets'], 'phishing_0')\n",
    "rules_df.to_csv('pattern_mining/rules_0_2.csv')\n",
    "rules_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999333</td>\n",
       "      <td>(qty_-_file_0.0_10.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.980867</td>\n",
       "      <td>(qty_params_0.0_4.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.980867</td>\n",
       "      <td>(qty_&amp;_params_0.0_3.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.978900</td>\n",
       "      <td>(qty_/_params_0.0_1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.978833</td>\n",
       "      <td>(qty___params_0.0_2.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114872</th>\n",
       "      <td>0.303267</td>\n",
       "      <td>(qty___file_0.0_3.0, num_numeric_chars_4.0_170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114873</th>\n",
       "      <td>0.302200</td>\n",
       "      <td>(qty___file_0.0_3.0, num_numeric_chars_4.0_170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114874</th>\n",
       "      <td>0.302200</td>\n",
       "      <td>(qty___file_0.0_3.0, num_numeric_chars_4.0_170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114875</th>\n",
       "      <td>0.300467</td>\n",
       "      <td>(qty_._params_0.0_2.0, num_numeric_chars_4.0_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114876</th>\n",
       "      <td>0.300300</td>\n",
       "      <td>(qty_=_directory_0.0_1.0, params_length_0.0_15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114877 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         support                                           itemsets\n",
       "0       0.999333                              (qty_-_file_0.0_10.0)\n",
       "1       0.980867                               (qty_params_0.0_4.0)\n",
       "2       0.980867                             (qty_&_params_0.0_3.0)\n",
       "3       0.978900                             (qty_/_params_0.0_1.0)\n",
       "4       0.978833                             (qty___params_0.0_2.0)\n",
       "...          ...                                                ...\n",
       "114872  0.303267  (qty___file_0.0_3.0, num_numeric_chars_4.0_170...\n",
       "114873  0.302200  (qty___file_0.0_3.0, num_numeric_chars_4.0_170...\n",
       "114874  0.302200  (qty___file_0.0_3.0, num_numeric_chars_4.0_170...\n",
       "114875  0.300467  (qty_._params_0.0_2.0, num_numeric_chars_4.0_1...\n",
       "114876  0.300300  (qty_=_directory_0.0_1.0, params_length_0.0_15...\n",
       "\n",
       "[114877 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Itemset</th>\n",
       "      <th>Antecedent Support</th>\n",
       "      <th>Union Support</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(qty_vowels_domain_7.0_23.0, qty_._domain_1.0_...</td>\n",
       "      <td>0.068363</td>\n",
       "      <td>0.055438</td>\n",
       "      <td>0.810934</td>\n",
       "      <td>2.162492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(qty_vowels_domain_7.0_23.0, qty___file_0.0_3....</td>\n",
       "      <td>0.068175</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.812615</td>\n",
       "      <td>2.166972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(qty_vowels_domain_7.0_23.0, domain_in_subdoma...</td>\n",
       "      <td>0.067975</td>\n",
       "      <td>0.055050</td>\n",
       "      <td>0.809857</td>\n",
       "      <td>2.159618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(qty_._params_0.0_2.0, qty_vowels_domain_7.0_2...</td>\n",
       "      <td>0.067725</td>\n",
       "      <td>0.054800</td>\n",
       "      <td>0.809155</td>\n",
       "      <td>2.157746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(email_in_url_0, qty_vowels_domain_7.0_23.0, q...</td>\n",
       "      <td>0.067625</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.808872</td>\n",
       "      <td>2.156993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4665</th>\n",
       "      <td>(num_numeric_chars_4.0_170.01, qty_@_params_0,...</td>\n",
       "      <td>0.045075</td>\n",
       "      <td>0.037625</td>\n",
       "      <td>0.834720</td>\n",
       "      <td>2.225920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4666</th>\n",
       "      <td>(num_numeric_chars_4.0_170.01, qty_-_file_0.0_...</td>\n",
       "      <td>0.045913</td>\n",
       "      <td>0.038762</td>\n",
       "      <td>0.844269</td>\n",
       "      <td>2.251384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4667</th>\n",
       "      <td>(num_numeric_chars_4.0_170.01, qty_&amp;_url_0.0_3...</td>\n",
       "      <td>0.045288</td>\n",
       "      <td>0.038525</td>\n",
       "      <td>0.850676</td>\n",
       "      <td>2.268470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4668</th>\n",
       "      <td>(num_numeric_chars_4.0_170.01, qty_=_params_0....</td>\n",
       "      <td>0.045150</td>\n",
       "      <td>0.038187</td>\n",
       "      <td>0.845792</td>\n",
       "      <td>2.255445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4669</th>\n",
       "      <td>(num_numeric_chars_4.0_170.01, qty_=_params_0....</td>\n",
       "      <td>0.044463</td>\n",
       "      <td>0.037887</td>\n",
       "      <td>0.852123</td>\n",
       "      <td>2.272327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4670 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Itemset  Antecedent Support  \\\n",
       "0     (qty_vowels_domain_7.0_23.0, qty_._domain_1.0_...            0.068363   \n",
       "1     (qty_vowels_domain_7.0_23.0, qty___file_0.0_3....            0.068175   \n",
       "2     (qty_vowels_domain_7.0_23.0, domain_in_subdoma...            0.067975   \n",
       "3     (qty_._params_0.0_2.0, qty_vowels_domain_7.0_2...            0.067725   \n",
       "4     (email_in_url_0, qty_vowels_domain_7.0_23.0, q...            0.067625   \n",
       "...                                                 ...                 ...   \n",
       "4665  (num_numeric_chars_4.0_170.01, qty_@_params_0,...            0.045075   \n",
       "4666  (num_numeric_chars_4.0_170.01, qty_-_file_0.0_...            0.045913   \n",
       "4667  (num_numeric_chars_4.0_170.01, qty_&_url_0.0_3...            0.045288   \n",
       "4668  (num_numeric_chars_4.0_170.01, qty_=_params_0....            0.045150   \n",
       "4669  (num_numeric_chars_4.0_170.01, qty_=_params_0....            0.044463   \n",
       "\n",
       "      Union Support  Confidence      Lift  \n",
       "0          0.055438    0.810934  2.162492  \n",
       "1          0.055400    0.812615  2.166972  \n",
       "2          0.055050    0.809857  2.159618  \n",
       "3          0.054800    0.809155  2.157746  \n",
       "4          0.054700    0.808872  2.156993  \n",
       "...             ...         ...       ...  \n",
       "4665       0.037625    0.834720  2.225920  \n",
       "4666       0.038762    0.844269  2.251384  \n",
       "4667       0.038525    0.850676  2.268470  \n",
       "4668       0.038187    0.845792  2.255445  \n",
       "4669       0.037887    0.852123  2.272327  \n",
       "\n",
       "[4670 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_df = generate_association_rules(df, frequent_itemset_1['itemsets'], 'phishing_1')\n",
    "rules_df.to_csv('pattern_mining/rules_1_2.csv')\n",
    "rules_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
