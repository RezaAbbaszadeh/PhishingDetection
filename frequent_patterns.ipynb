{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filepath = \"features/url_features.csv\"  # Replace with your dataset file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate columns (with different names):\n",
      "Columns ['qty_._url', 'num_dots'] have identical values.\n",
      "Columns ['qty_-_url', 'num_dash'] have identical values.\n",
      "Columns ['qty___url', 'num_underscore'] have identical values.\n",
      "Columns ['qty_&_url', 'num_ampersand'] have identical values.\n",
      "Columns ['qty_#_url', 'num_hash'] have identical values.\n",
      "Columns ['qty_%_url', 'num_percent'] have identical values.\n",
      "Columns ['length_url', 'url_length'] have identical values.\n",
      "Columns ['qty_._domain', 'subdomain_level', 'subdomain_count'] have identical values.\n",
      "Columns ['qty_-_domain', 'num_dash_in_hostname'] have identical values.\n",
      "Columns ['domain_length', 'hostname_length'] have identical values.\n",
      "Columns ['domain_in_ip', 'ip_address', 'ip_address_in_url'] have identical values.\n",
      "Columns ['directory_length', 'path_length'] have identical values.\n",
      "Columns ['params_length', 'query_length'] have identical values.\n",
      "Columns ['qty_params', 'num_query_components'] have identical values.\n",
      "Columns ['at_symbol', 'at_symbol_in_url'] have identical values.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(filepath)\n",
    "df = df.loc[:, df.nunique() > 1]\n",
    "\n",
    "# Step 1: Create a dictionary to store column data as tuples\n",
    "column_map = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    column_values = tuple(df[col])  # Convert column values to a tuple\n",
    "    column_map.setdefault(column_values, []).append(col)\n",
    "\n",
    "# Step 2: Identify columns with duplicate data but different names\n",
    "duplicate_columns = {k: v for k, v in column_map.items() if len(v) > 1}\n",
    "\n",
    "# Display results\n",
    "print(\"Duplicate columns (with different names):\")\n",
    "for values, columns in duplicate_columns.items():\n",
    "    print(f\"Columns {columns} have identical values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 144)\n",
      "(80000, 107)\n",
      "(80000, 90)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(filepath)\n",
    "print(df.shape)\n",
    "df = df.loc[:, df.nunique() > 1]\n",
    "print(df.shape)\n",
    "\n",
    "column_map = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    column_values = tuple(df[col])  # Convert column values to a tuple\n",
    "    column_map.setdefault(column_values, []).append(col)\n",
    "\n",
    "# Step 2: Identify columns with duplicate data\n",
    "duplicate_columns = {k: v for k, v in column_map.items() if len(v) > 1}\n",
    "\n",
    "# Step 3: Keep only one column from each group\n",
    "columns_to_drop = [cols[1:] for cols in duplicate_columns.values()]  # Get all but the first column in each group\n",
    "columns_to_drop = [col for group in columns_to_drop for col in group]  # Flatten the list of lists\n",
    "\n",
    "# Drop duplicate columns\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qty_._url', 'qty_-_url', 'qty_/_url', 'qty_?_url', 'qty_=_url',\n",
       "       'qty_@_url', 'qty_&_url', 'qty_tld_url', 'length_url', 'email_in_url',\n",
       "       'qty_._domain', 'qty_-_domain', 'qty_vowels_domain', 'domain_length',\n",
       "       'qty_._directory', 'qty_-_directory', 'qty___directory',\n",
       "       'qty_/_directory', 'directory_length', 'qty_._file', 'qty_-_file',\n",
       "       'qty___file', 'file_length', 'qty_._params', 'qty___params',\n",
       "       'qty_=_params', 'qty_@_params', 'qty_&_params', 'params_length',\n",
       "       'qty_params', 'path_level', 'at_symbol', 'num_numeric_chars',\n",
       "       'no_https', 'random_string', 'domain_in_subdomains', 'domain_in_paths',\n",
       "       'num_sensitive_words', 'long_url', 'prefix_suffix_in_domain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "X = df.drop(columns=['rec_id', 'phishing'])\n",
    "y = df['phishing']\n",
    "\n",
    "# Apply SelectKBest with mutual information\n",
    "k = 40  # Number of top features to select\n",
    "selector = SelectKBest(mutual_info_classif, k=k)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "\n",
    "# Create a DataFrame with the selected features\n",
    "X_selected = pd.DataFrame(X_new, columns=selected_features)\n",
    "\n",
    "# Display the selected features\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 144)\n",
      "(80000, 41)\n",
      "linear qty_?_url [0. 1. 2.]\n",
      "linear qty_=_url [ 0.  4.  7. 11.]\n",
      "linear qty_&_url [ 0.  3.  6. 10.]\n",
      "linear qty_-_domain [0. 3. 4. 5.]\n",
      "linear qty___directory [0. 4. 5. 9.]\n",
      "linear qty_=_directory [0. 1. 2.]\n",
      "linear qty_-_file [ 0. 10. 11. 15.]\n",
      "linear qty___file [0. 3. 4. 8.]\n",
      "linear qty_._params [ 0.  2.  4. 21.]\n",
      "linear qty___params [ 0.  2.  3. 18.]\n",
      "linear qty_/_params [0. 1. 3. 9.]\n",
      "linear qty_=_params [ 0.  4.  7. 11.]\n",
      "linear qty_&_params [0. 3. 5. 9.]\n",
      "linear params_length [  0.       157.       208.       462.000004 462.004   ]\n",
      "linear qty_params [ 0.  4.  6. 10.]\n",
      "linear domain_in_subdomains [0. 1. 2.]\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(filepath, n_bins=4):\n",
    "    \"\"\"\n",
    "    Loads the dataset and converts features into itemsets for association rule mining.\n",
    "    Binary features are converted to <feature_name>_1 or <feature_name>_0.\n",
    "    Numerical features are binned into ranges and converted to <feature_name>_<start_value>_<end_value>.\n",
    "    Assumes the column 'phishing' is the target class.\n",
    "    \n",
    "    Parameters:\n",
    "        filepath (str): Path to the CSV file.\n",
    "        n_bins (int): Number of bins for numerical features.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame where rows represent itemsets.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(df.shape)\n",
    "    df = df[selected_features.tolist() + ['phishing']]\n",
    "    df = df.iloc[:, :]  # For testing on a smaller subset\n",
    "    print(df.shape)\n",
    "\n",
    "    itemsets = []\n",
    "\n",
    "    bins_dict = {}\n",
    "    for col in df.columns:\n",
    "        if col!='phishing' and (df[col].dtype in ['int64', 'float64']) and df[col].nunique() > 2:\n",
    "            df[col] = df[col].clip(lower=df[col].min(), \n",
    "                                               upper=df[col].quantile(0.999))\n",
    "            if df[col].nunique() <= 2:\n",
    "                continue\n",
    "            bins = pd.qcut(df[col], q=n_bins, duplicates='drop', retbins=True)[1]\n",
    "            if len(bins) < 3:\n",
    "                bins = pd.cut(df[col], \n",
    "                              bins=[df[col].min(), df[col].quantile(0.01), df[col].quantile(0.05), df[col].quantile(0.1), \n",
    "                                    df[col].quantile(0.2),df[col].quantile(0.4), df[col].quantile(0.99), \n",
    "                                    df[col].quantile(0.995), df[col].quantile(0.999), df[col].max()],\n",
    "                                       duplicates='drop', retbins=True)[1]\n",
    "                if len(bins) == 2:\n",
    "                    bins = np.insert(bins, 1, (bins[0]+bins[1])/2)\n",
    "                print('linear', col, bins)\n",
    "            bin_labels = [f\"{col}_{round(bins[i], 2)}_{round(bins[i+1], 2)}\" for i in range(len(bins) - 1)]\n",
    "            bins_dict[col] = {'bins': bins, 'labels': bin_labels}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if index % 1000 == 0:\n",
    "            print(index)\n",
    "        itemset = []\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if df[col].dtype in ['int64', 'float64'] and df[col].nunique() > 2:\n",
    "                # Numerical feature: binning into ranges\n",
    "                bins = bins_dict[col]['bins']\n",
    "                bin_labels = bins_dict[col]['labels']\n",
    "                bin_idx = np.digitize(row[col], bins) - 1\n",
    "                bin_idx = min(bin_idx, len(bin_labels) - 1)  # Ensure index is within range\n",
    "                itemset.append(bin_labels[bin_idx])\n",
    "            else:\n",
    "                # Binary/categorical feature: encode as <feature_name>_value\n",
    "                itemset.append(f\"{col}_{int(row[col])}\")\n",
    "        \n",
    "        itemsets.append(itemset)\n",
    "\n",
    "    # Convert itemsets into a DataFrame for analysis\n",
    "    transactions_df = pd.DataFrame({'itemsets': itemsets})\n",
    "    return transactions_df\n",
    "\n",
    "# Load and preprocess data\n",
    "df = preprocess_data(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('pattern_mining/preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            itemsets\n",
       "0  [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "1  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "2  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "3  [qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...\n",
       "4  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>[qty_._url_0.0_2.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                itemsets\n",
       "0      [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "1      [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "2      [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "3      [qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...\n",
       "4      [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "...                                                  ...\n",
       "79995  [qty_._url_0.0_2.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "79996  [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "79997  [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "79998  [qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...\n",
       "79999  [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "\n",
       "[80000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "df = pd.read_csv('pattern_mining/preprocessed.csv')\n",
    "df['itemsets'] = df['itemsets'].apply(ast.literal_eval)\n",
    "df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           itemsets\n",
       "0           0  [qty_._url_2.0_3.0, qty_-_url_0.0_1.0, qty_/_u...\n",
       "1           1  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "2           2  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_...\n",
       "3           3  [qty_._url_3.0_23.0, qty_-_url_1.0_2.0, qty_/_...\n",
       "4           4  [qty_._url_3.0_23.0, qty_-_url_0.0_1.0, qty_/_..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 55)\n",
      "done\n",
      "(50000, 52)\n",
      "done\n",
      "Frequent itemsets including phishing_0:\n",
      "       support                                           itemsets\n",
      "0      0.99948                                      (qty_@_url_0)\n",
      "1      0.99788                          (params_length_0.0_157.0)\n",
      "2      0.99600                             (qty___params_0.0_2.0)\n",
      "3      0.99518                                (domain_in_paths_0)\n",
      "4      0.99386                               (qty_params_0.0_4.0)\n",
      "...        ...                                                ...\n",
      "93761  0.67772  (domain_in_subdomains_0.0_1.0, email_in_url_0,...\n",
      "93762  0.67772  (domain_in_subdomains_0.0_1.0, email_in_url_0,...\n",
      "93763  0.67772  (domain_in_subdomains_0.0_1.0, email_in_url_0,...\n",
      "93764  0.67772  (domain_in_subdomains_0.0_1.0, email_in_url_0,...\n",
      "93765  0.67772  (domain_in_subdomains_0.0_1.0, email_in_url_0,...\n",
      "\n",
      "[93766 rows x 2 columns]\n",
      "(30000, 58)\n",
      "done\n",
      "(30000, 50)\n",
      "done\n",
      "Frequent itemsets including phishing_1:\n",
      "        support                                           itemsets\n",
      "0      0.999333                              (qty_-_file_0.0_10.0)\n",
      "1      0.996467                               (qty___file_0.0_3.0)\n",
      "2      0.980867                             (qty_&_params_0.0_3.0)\n",
      "3      0.979533                                (qty_&_url_0.0_3.0)\n",
      "4      0.976300                             (qty_=_params_0.0_4.0)\n",
      "...         ...                                                ...\n",
      "69608  0.300800  (at_symbol_0, params_length_0.0_157.0, qty_._p...\n",
      "69609  0.300667  (at_symbol_0, params_length_0.0_157.0, qty___p...\n",
      "69610  0.302567  (email_in_url_0, num_numeric_chars_4.0_170.01,...\n",
      "69611  0.300800  (email_in_url_0, qty_._params_0.0_2.0, num_num...\n",
      "69612  0.300667  (email_in_url_0, num_numeric_chars_4.0_170.01,...\n",
      "\n",
      "[69613 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def mine_frequent_itemsets(df_itemsets, label, min_support=0.01):\n",
    "    \"\"\"\n",
    "    Mines frequent patterns for transactions containing 'phishing_1',\n",
    "    and appends 'phishing_1' to all resulting frequent itemsets.\n",
    "    \n",
    "    Parameters:\n",
    "        df_itemsets (pd.DataFrame): DataFrame with a column 'itemsets' containing lists of items.\n",
    "        min_support (float): Minimum support threshold for frequent itemsets.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Frequent itemsets including 'phishing_1' with their support values.\n",
    "    \"\"\"\n",
    "    # Filter transactions to only include those containing 'phishing_1'\n",
    "\n",
    "    random.seed = 42\n",
    "    f = list(selected_features)\n",
    "    random.shuffle(f)\n",
    "    features = [tuple(f[:20]), tuple(f[20:])]\n",
    "\n",
    "    all_frequent_itemsets = []\n",
    "    \n",
    "    for feature_set in features:\n",
    "    # Remove 'phishing_1' from each transaction (to avoid redundancy in mining)\n",
    "        transactions = df_itemsets['itemsets']\n",
    "        filtered_transactions = [t for t in transactions if label in t]\n",
    "        filtered_transactions = [\n",
    "            [item for item in t if (item != label and item.startswith(feature_set))] for t in filtered_transactions\n",
    "        ]\n",
    "        \n",
    "        # Convert transactions into a one-hot encoded DataFrame\n",
    "        te = TransactionEncoder()\n",
    "        one_hot = te.fit_transform(filtered_transactions)\n",
    "        one_hot_df = pd.DataFrame(one_hot, columns=te.columns_)\n",
    "        print(one_hot_df.shape)\n",
    "        \n",
    "        # Mine frequent patterns from filtered transactions\n",
    "        frequent_itemsets = fpgrowth(one_hot_df, min_support=min_support, use_colnames=True)\n",
    "        # frequent_itemsets = apriori(one_hot_df, min_support=min_support, use_colnames=True)\n",
    "        \n",
    "        # Append 'phishing_1' to all itemsets\n",
    "        # frequent_itemsets['itemsets'] = frequent_itemsets['itemsets'].apply(lambda x: x | {label})\n",
    "        all_frequent_itemsets.append(frequent_itemsets)\n",
    "        print('done')\n",
    "        \n",
    "    combined_frequent_itemsets = pd.concat(all_frequent_itemsets, ignore_index=True)\n",
    "    print(f\"Frequent itemsets including {label}:\")\n",
    "    print(combined_frequent_itemsets)\n",
    "    \n",
    "    return combined_frequent_itemsets\n",
    "\n",
    "\n",
    "min_support = 0.3  # Adjust minimum support threshold\n",
    "# Mine frequent itemsets\n",
    "frequent_itemset_0 = mine_frequent_itemsets(df, 'phishing_0', min_support)\n",
    "frequent_itemset_1 = mine_frequent_itemsets(df, 'phishing_1', min_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6399\n",
      "        support                                           itemsets\n",
      "2058    0.75776  (qty_@_params_0, qty___file_0.0_3.0, prefix_su...\n",
      "3082    0.78816  (qty_@_params_0, qty_tld_url_3.0_8.0, qty___fi...\n",
      "3594    0.74102  (qty_@_params_0, qty_tld_url_3.0_8.0, qty___fi...\n",
      "3850    0.71328  (qty_@_params_0, qty_tld_url_3.0_8.0, prefix_s...\n",
      "3978    0.70116  (qty_@_params_0, qty_tld_url_3.0_8.0, qty___fi...\n",
      "...         ...                                                ...\n",
      "148731  0.52510  (qty_&_params_0.0_3.0, qty_=_url_0.0_4.0, qty_...\n",
      "148732  0.52510  (qty_&_params_0.0_3.0, qty_=_url_0.0_4.0, qty_...\n",
      "148733  0.52510  (qty_&_params_0.0_3.0, qty_=_url_0.0_4.0, qty_...\n",
      "148734  0.52510  (qty_&_params_0.0_3.0, qty_=_url_0.0_4.0, qty_...\n",
      "148735  0.52510  (qty_&_params_0.0_3.0, qty_=_url_0.0_4.0, qty_...\n",
      "\n",
      "[6399 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "filtered = frequent_itemset_0[frequent_itemset_0['itemsets'].apply(len) > 10]\n",
    "print(len(filtered))\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_association_rules(df, frequent_itemsets, label, min_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Generates association rules with a specified consequent (label), \n",
    "    a minimum confidence threshold, and calculates lift.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing a column 'itemsets' with transactions (lists of items).\n",
    "        frequent_itemsets (list): List of frequent itemsets.\n",
    "        label (str): Consequent item (e.g., 'phishing_1').\n",
    "        min_threshold (float): Minimum confidence threshold.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with generated association rules including lift.\n",
    "    \"\"\"\n",
    "    # Convert transactions into a one-hot encoded DataFrame\n",
    "    transactions = df['itemsets']\n",
    "    te = TransactionEncoder()\n",
    "    one_hot = te.fit_transform(transactions)\n",
    "    one_hot_df = pd.DataFrame(one_hot, columns=te.columns_)\n",
    "\n",
    "    # Calculate support for the consequent (label)\n",
    "    total_transactions = len(one_hot_df)\n",
    "    consequent_support = one_hot_df[label].sum() / total_transactions\n",
    "\n",
    "    # Initialize results\n",
    "    results = []\n",
    "    c = 0\n",
    "    for itemset in frequent_itemsets:\n",
    "        c+=1\n",
    "        if c%1000==0:\n",
    "            print(c)\n",
    "        # Convert itemset to list\n",
    "        itemset_list = list(itemset)\n",
    "\n",
    "        # Calculate support of antecedent\n",
    "        antecedent_support = np.all(one_hot_df[itemset_list].values, axis=1).sum() / total_transactions\n",
    "\n",
    "        # Calculate support of (antecedent ∪ label)\n",
    "        union_support = np.all(one_hot_df[itemset_list + [label]].values, axis=1).sum() / total_transactions\n",
    "\n",
    "        # Calculate confidence\n",
    "        confidence = union_support / antecedent_support if antecedent_support > 0 else 0\n",
    "\n",
    "        # Calculate lift\n",
    "        lift = confidence / consequent_support if consequent_support > 0 else 0\n",
    "\n",
    "        if confidence > min_threshold:\n",
    "            results.append({\n",
    "                \"Itemset\": itemset,\n",
    "                \"Antecedent Support\": antecedent_support,\n",
    "                \"Union Support\": union_support,\n",
    "                \"Confidence\": confidence,\n",
    "                \"Lift\": lift\n",
    "            })\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Itemset</th>\n",
       "      <th>Antecedent Support</th>\n",
       "      <th>Union Support</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(path_level_1.0_2.0)</td>\n",
       "      <td>0.280900</td>\n",
       "      <td>0.210338</td>\n",
       "      <td>0.748799</td>\n",
       "      <td>1.198078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(file_length_13.0_148.0)</td>\n",
       "      <td>0.260663</td>\n",
       "      <td>0.222562</td>\n",
       "      <td>0.853834</td>\n",
       "      <td>1.366134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(qty_-_directory_2.0_18.0)</td>\n",
       "      <td>0.255937</td>\n",
       "      <td>0.236313</td>\n",
       "      <td>0.923321</td>\n",
       "      <td>1.477314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(qty_._url_2.0_3.0)</td>\n",
       "      <td>0.515925</td>\n",
       "      <td>0.363675</td>\n",
       "      <td>0.704899</td>\n",
       "      <td>1.127838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(qty_@_url_0, qty_._domain_2.0_6.0)</td>\n",
       "      <td>0.706975</td>\n",
       "      <td>0.497462</td>\n",
       "      <td>0.703649</td>\n",
       "      <td>1.125839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60383</th>\n",
       "      <td>(domain_in_subdomains_0.0_1.0, email_in_url_0,...</td>\n",
       "      <td>0.543500</td>\n",
       "      <td>0.423575</td>\n",
       "      <td>0.779347</td>\n",
       "      <td>1.246955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60384</th>\n",
       "      <td>(domain_in_subdomains_0.0_1.0, email_in_url_0,...</td>\n",
       "      <td>0.543500</td>\n",
       "      <td>0.423575</td>\n",
       "      <td>0.779347</td>\n",
       "      <td>1.246955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60385</th>\n",
       "      <td>(domain_in_subdomains_0.0_1.0, email_in_url_0,...</td>\n",
       "      <td>0.543650</td>\n",
       "      <td>0.423575</td>\n",
       "      <td>0.779132</td>\n",
       "      <td>1.246611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60386</th>\n",
       "      <td>(domain_in_subdomains_0.0_1.0, email_in_url_0,...</td>\n",
       "      <td>0.543500</td>\n",
       "      <td>0.423575</td>\n",
       "      <td>0.779347</td>\n",
       "      <td>1.246955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60387</th>\n",
       "      <td>(domain_in_subdomains_0.0_1.0, email_in_url_0,...</td>\n",
       "      <td>0.543500</td>\n",
       "      <td>0.423575</td>\n",
       "      <td>0.779347</td>\n",
       "      <td>1.246955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60388 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Itemset  Antecedent Support  \\\n",
       "0                                   (path_level_1.0_2.0)            0.280900   \n",
       "1                               (file_length_13.0_148.0)            0.260663   \n",
       "2                             (qty_-_directory_2.0_18.0)            0.255937   \n",
       "3                                    (qty_._url_2.0_3.0)            0.515925   \n",
       "4                    (qty_@_url_0, qty_._domain_2.0_6.0)            0.706975   \n",
       "...                                                  ...                 ...   \n",
       "60383  (domain_in_subdomains_0.0_1.0, email_in_url_0,...            0.543500   \n",
       "60384  (domain_in_subdomains_0.0_1.0, email_in_url_0,...            0.543500   \n",
       "60385  (domain_in_subdomains_0.0_1.0, email_in_url_0,...            0.543650   \n",
       "60386  (domain_in_subdomains_0.0_1.0, email_in_url_0,...            0.543500   \n",
       "60387  (domain_in_subdomains_0.0_1.0, email_in_url_0,...            0.543500   \n",
       "\n",
       "       Union Support  Confidence      Lift  \n",
       "0           0.210338    0.748799  1.198078  \n",
       "1           0.222562    0.853834  1.366134  \n",
       "2           0.236313    0.923321  1.477314  \n",
       "3           0.363675    0.704899  1.127838  \n",
       "4           0.497462    0.703649  1.125839  \n",
       "...              ...         ...       ...  \n",
       "60383       0.423575    0.779347  1.246955  \n",
       "60384       0.423575    0.779347  1.246955  \n",
       "60385       0.423575    0.779132  1.246611  \n",
       "60386       0.423575    0.779347  1.246955  \n",
       "60387       0.423575    0.779347  1.246955  \n",
       "\n",
       "[60388 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_df = generate_association_rules(df, frequent_itemset_0['itemsets'], 'phishing_0')\n",
    "rules_df.to_csv('pattern_mining/rules_0.csv')\n",
    "rules_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999333</td>\n",
       "      <td>(qty_-_file_0.0_10.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.980867</td>\n",
       "      <td>(qty_params_0.0_4.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.980867</td>\n",
       "      <td>(qty_&amp;_params_0.0_3.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.978900</td>\n",
       "      <td>(qty_/_params_0.0_1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.978833</td>\n",
       "      <td>(qty___params_0.0_2.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114872</th>\n",
       "      <td>0.303267</td>\n",
       "      <td>(qty___file_0.0_3.0, num_numeric_chars_4.0_170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114873</th>\n",
       "      <td>0.302200</td>\n",
       "      <td>(qty___file_0.0_3.0, num_numeric_chars_4.0_170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114874</th>\n",
       "      <td>0.302200</td>\n",
       "      <td>(qty___file_0.0_3.0, num_numeric_chars_4.0_170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114875</th>\n",
       "      <td>0.300467</td>\n",
       "      <td>(qty_._params_0.0_2.0, num_numeric_chars_4.0_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114876</th>\n",
       "      <td>0.300300</td>\n",
       "      <td>(qty_=_directory_0.0_1.0, params_length_0.0_15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114877 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         support                                           itemsets\n",
       "0       0.999333                              (qty_-_file_0.0_10.0)\n",
       "1       0.980867                               (qty_params_0.0_4.0)\n",
       "2       0.980867                             (qty_&_params_0.0_3.0)\n",
       "3       0.978900                             (qty_/_params_0.0_1.0)\n",
       "4       0.978833                             (qty___params_0.0_2.0)\n",
       "...          ...                                                ...\n",
       "114872  0.303267  (qty___file_0.0_3.0, num_numeric_chars_4.0_170...\n",
       "114873  0.302200  (qty___file_0.0_3.0, num_numeric_chars_4.0_170...\n",
       "114874  0.302200  (qty___file_0.0_3.0, num_numeric_chars_4.0_170...\n",
       "114875  0.300467  (qty_._params_0.0_2.0, num_numeric_chars_4.0_1...\n",
       "114876  0.300300  (qty_=_directory_0.0_1.0, params_length_0.0_15...\n",
       "\n",
       "[114877 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Itemset</th>\n",
       "      <th>Antecedent Support</th>\n",
       "      <th>Union Support</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(qty_._directory_1.0_9.0, file_length_6.0_13.0)</td>\n",
       "      <td>0.157625</td>\n",
       "      <td>0.119712</td>\n",
       "      <td>0.759477</td>\n",
       "      <td>2.025271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(qty_._directory_1.0_9.0, qty_-_file_0.0_10.0,...</td>\n",
       "      <td>0.157625</td>\n",
       "      <td>0.119712</td>\n",
       "      <td>0.759477</td>\n",
       "      <td>2.025271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(qty_._directory_1.0_9.0, qty___file_0.0_3.0, ...</td>\n",
       "      <td>0.157600</td>\n",
       "      <td>0.119712</td>\n",
       "      <td>0.759597</td>\n",
       "      <td>2.025592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(qty_._directory_1.0_9.0, qty_&amp;_params_0.0_3.0...</td>\n",
       "      <td>0.152575</td>\n",
       "      <td>0.115138</td>\n",
       "      <td>0.754629</td>\n",
       "      <td>2.012344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(qty_._directory_1.0_9.0, qty_&amp;_url_0.0_3.0, f...</td>\n",
       "      <td>0.152512</td>\n",
       "      <td>0.115075</td>\n",
       "      <td>0.754528</td>\n",
       "      <td>2.012076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>(qty_-_directory_0.0_2.0, qty_._params_0.0_2.0...</td>\n",
       "      <td>0.138875</td>\n",
       "      <td>0.112812</td>\n",
       "      <td>0.812331</td>\n",
       "      <td>2.166217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>(qty_-_directory_0.0_2.0, qty_._params_0.0_2.0...</td>\n",
       "      <td>0.138525</td>\n",
       "      <td>0.112525</td>\n",
       "      <td>0.812308</td>\n",
       "      <td>2.166155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>(qty_-_directory_0.0_2.0, domain_in_paths_0, q...</td>\n",
       "      <td>0.138662</td>\n",
       "      <td>0.112625</td>\n",
       "      <td>0.812224</td>\n",
       "      <td>2.165930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>(qty_-_directory_0.0_2.0, email_in_url_0, at_s...</td>\n",
       "      <td>0.138925</td>\n",
       "      <td>0.112662</td>\n",
       "      <td>0.810959</td>\n",
       "      <td>2.162558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>(qty_._params_0.0_2.0, qty_-_directory_0.0_2.0...</td>\n",
       "      <td>0.164862</td>\n",
       "      <td>0.115450</td>\n",
       "      <td>0.700281</td>\n",
       "      <td>1.867415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>884 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Itemset  Antecedent Support  \\\n",
       "0      (qty_._directory_1.0_9.0, file_length_6.0_13.0)            0.157625   \n",
       "1    (qty_._directory_1.0_9.0, qty_-_file_0.0_10.0,...            0.157625   \n",
       "2    (qty_._directory_1.0_9.0, qty___file_0.0_3.0, ...            0.157600   \n",
       "3    (qty_._directory_1.0_9.0, qty_&_params_0.0_3.0...            0.152575   \n",
       "4    (qty_._directory_1.0_9.0, qty_&_url_0.0_3.0, f...            0.152512   \n",
       "..                                                 ...                 ...   \n",
       "879  (qty_-_directory_0.0_2.0, qty_._params_0.0_2.0...            0.138875   \n",
       "880  (qty_-_directory_0.0_2.0, qty_._params_0.0_2.0...            0.138525   \n",
       "881  (qty_-_directory_0.0_2.0, domain_in_paths_0, q...            0.138662   \n",
       "882  (qty_-_directory_0.0_2.0, email_in_url_0, at_s...            0.138925   \n",
       "883  (qty_._params_0.0_2.0, qty_-_directory_0.0_2.0...            0.164862   \n",
       "\n",
       "     Union Support  Confidence      Lift  \n",
       "0         0.119712    0.759477  2.025271  \n",
       "1         0.119712    0.759477  2.025271  \n",
       "2         0.119712    0.759597  2.025592  \n",
       "3         0.115138    0.754629  2.012344  \n",
       "4         0.115075    0.754528  2.012076  \n",
       "..             ...         ...       ...  \n",
       "879       0.112812    0.812331  2.166217  \n",
       "880       0.112525    0.812308  2.166155  \n",
       "881       0.112625    0.812224  2.165930  \n",
       "882       0.112662    0.810959  2.162558  \n",
       "883       0.115450    0.700281  1.867415  \n",
       "\n",
       "[884 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_df = generate_association_rules(df, frequent_itemset_1['itemsets'], 'phishing_1')\n",
    "rules_df.to_csv('pattern_mining/rules_1.csv')\n",
    "rules_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
